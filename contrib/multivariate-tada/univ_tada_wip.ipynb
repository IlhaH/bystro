{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "e09JyycNa9Pc"
      },
      "outputs": [],
      "source": [
        "from typing import Any, Tuple, Optional\n",
        "import numpy as np\n",
        "from scipy.stats import nbinom, gamma, poisson, hypergeom\n",
        "import scipy.integrate as integrate\n",
        "import os\n",
        "import copy\n",
        "import multiprocessing\n",
        "import uuid\n",
        "from math import exp, log\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sfw_Krk1Efqz",
        "outputId": "03541891-e84e-428e-c385-9c7eff82ac13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CALCULATION OF TADA TEST STATISTICS\n",
            "checking the input for consistent variable names\n",
            "working on :: cls1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5000 [00:00<?, ?it/s]\n",
            "  2%|▏         | 100/5000 [00:00<00:10, 462.59it/s]\n",
            "  4%|▍         | 200/5000 [00:00<00:03, 1312.75it/s]\n",
            "  6%|▌         | 300/5000 [00:00<00:01, 2384.87it/s]\n",
            "  8%|▊         | 400/5000 [00:00<00:01, 2957.97it/s]\n",
            " 10%|█         | 500/5000 [00:00<00:01, 2348.24it/s]\n",
            " 12%|█▏        | 600/5000 [00:00<00:01, 3262.97it/s]\n",
            " 14%|█▍        | 700/5000 [00:00<00:01, 2987.87it/s]\n",
            " 16%|█▌        | 800/5000 [00:00<00:01, 2947.79it/s]\n",
            " 18%|█▊        | 900/5000 [00:00<00:00, 4535.27it/s]\n",
            " 20%|██        | 1000/5000 [00:00<00:00, 6434.24it/s]\n",
            " 22%|██▏       | 1100/5000 [00:00<00:00, 7089.64it/s]\n",
            " 24%|██▍       | 1200/5000 [00:00<00:00, 11377.16it/s]\n",
            " 26%|██▌       | 1300/5000 [00:00<00:00, 4791.45it/s]\n",
            " 28%|██▊       | 1400/5000 [00:00<00:00, 9050.05it/s]\n",
            " 30%|███       | 1500/5000 [00:00<00:00, 8745.54it/s]\n",
            " 32%|███▏      | 1600/5000 [00:00<00:00, 8793.71it/s]\n",
            " 34%|███▍      | 1700/5000 [00:00<00:00, 15673.85it/s]\n",
            " 36%|███▌      | 1800/5000 [00:00<00:00, 9316.99it/s]\n",
            " 38%|███▊      | 1900/5000 [00:00<00:00, 10241.62it/s]\n",
            " 40%|████      | 2000/5000 [00:00<00:00, 14088.98it/s]\n",
            " 42%|████▏     | 2100/5000 [00:00<00:00, 13866.36it/s]\n",
            " 44%|████▍     | 2200/5000 [00:00<00:00, 19183.29it/s]\n",
            " 46%|████▌     | 2300/5000 [00:00<00:00, 11165.57it/s]\n",
            " 48%|████▊     | 2400/5000 [00:00<00:00, 15491.12it/s]\n",
            " 50%|█████     | 2500/5000 [00:00<00:00, 15680.65it/s]\n",
            " 52%|█████▏    | 2600/5000 [00:00<00:00, 9407.65it/s]\n",
            " 54%|█████▍    | 2700/5000 [00:00<00:00, 11634.31it/s]\n",
            " 56%|█████▌    | 2800/5000 [00:00<00:00, 23274.30it/s]\n",
            " 58%|█████▊    | 2900/5000 [00:00<00:00, 17964.11it/s]\n",
            " 60%|██████    | 3000/5000 [00:00<00:00, 16438.24it/s]\n",
            " 62%|██████▏   | 3100/5000 [00:00<00:00, 13464.07it/s]\n",
            " 64%|██████▍   | 3200/5000 [00:00<00:00, 17516.27it/s]\n",
            " 66%|██████▌   | 3300/5000 [00:00<00:00, 31185.75it/s]\n",
            " 68%|██████▊   | 3400/5000 [00:00<00:00, 31157.50it/s]\n",
            " 70%|███████   | 3500/5000 [00:00<00:00, 20674.81it/s]\n",
            " 72%|███████▏  | 3600/5000 [00:00<00:00, 17076.68it/s]\n",
            " 74%|███████▍  | 3700/5000 [00:00<00:00, 28482.30it/s]\n",
            " 76%|███████▌  | 3800/5000 [00:00<00:00, 21541.08it/s]\n",
            " 78%|███████▊  | 3900/5000 [00:00<00:00, 20379.19it/s]\n",
            " 80%|████████  | 4000/5000 [00:00<00:00, 26356.23it/s]\n",
            " 82%|████████▏ | 4100/5000 [00:00<00:00, 19259.00it/s]\n",
            " 84%|████████▍ | 4200/5000 [00:00<00:00, 39382.96it/s]\n",
            " 86%|████████▌ | 4300/5000 [00:00<00:00, 30048.41it/s]\n",
            " 88%|████████▊ | 4400/5000 [00:00<00:00, 12980.37it/s]\n",
            " 90%|█████████ | 4500/5000 [00:00<00:00, 23018.90it/s]\n",
            " 92%|█████████▏| 4600/5000 [00:00<00:00, 42645.77it/s]\n",
            " 94%|█████████▍| 4700/5000 [00:00<00:00, 21660.29it/s]\n",
            " 96%|█████████▌| 4800/5000 [00:00<00:00, 41569.43it/s]\n",
            " 98%|█████████▊| 4900/5000 [00:00<00:00, 21792.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "working on :: cls2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5000 [00:00<?, ?it/s]\n",
            "  2%|▏         | 100/5000 [00:00<00:19, 257.51it/s]\n",
            "  4%|▍         | 200/5000 [00:00<00:07, 603.48it/s]\n",
            "  6%|▌         | 300/5000 [00:00<00:04, 1165.05it/s]\n",
            "  8%|▊         | 400/5000 [00:00<00:01, 2526.89it/s]\n",
            " 10%|█         | 500/5000 [00:00<00:01, 2276.40it/s]\n",
            " 12%|█▏        | 600/5000 [00:00<00:02, 1629.44it/s]\n",
            " 14%|█▍        | 700/5000 [00:00<00:02, 1543.74it/s]\n",
            " 16%|█▌        | 800/5000 [00:00<00:01, 2324.73it/s]\n",
            " 18%|█▊        | 900/5000 [00:00<00:01, 2187.30it/s]\n",
            " 20%|██        | 1000/5000 [00:00<00:01, 2465.10it/s]\n",
            " 22%|██▏       | 1100/5000 [00:00<00:01, 3159.15it/s]\n",
            " 24%|██▍       | 1200/5000 [00:00<00:00, 6125.44it/s]\n",
            " 26%|██▌       | 1300/5000 [00:00<00:00, 4489.53it/s]\n",
            " 28%|██▊       | 1400/5000 [00:00<00:00, 6111.03it/s]\n",
            " 30%|███       | 1500/5000 [00:00<00:00, 6399.39it/s]\n",
            " 32%|███▏      | 1600/5000 [00:00<00:00, 5288.97it/s]\n",
            " 34%|███▍      | 1700/5000 [00:00<00:00, 11538.48it/s]\n",
            " 36%|███▌      | 1800/5000 [00:00<00:00, 10668.34it/s]\n",
            " 38%|███▊      | 1900/5000 [00:00<00:00, 6681.97it/s]\n",
            " 40%|████      | 2000/5000 [00:00<00:00, 7730.79it/s]\n",
            " 42%|████▏     | 2100/5000 [00:00<00:00, 12571.42it/s]\n",
            " 44%|████▍     | 2200/5000 [00:00<00:00, 9669.33it/s]\n",
            " 46%|████▌     | 2300/5000 [00:00<00:00, 8331.84it/s]\n",
            " 48%|████▊     | 2400/5000 [00:00<00:00, 14625.89it/s]\n",
            " 50%|█████     | 2500/5000 [00:00<00:00, 17042.01it/s]\n",
            " 52%|█████▏    | 2600/5000 [00:00<00:00, 11412.36it/s]\n",
            " 54%|█████▍    | 2700/5000 [00:00<00:00, 9728.35it/s]\n",
            " 56%|█████▌    | 2800/5000 [00:00<00:00, 9308.01it/s]\n",
            " 58%|█████▊    | 2900/5000 [00:00<00:00, 13317.18it/s]\n",
            " 60%|██████    | 3000/5000 [00:00<00:00, 17230.09it/s]\n",
            " 62%|██████▏   | 3100/5000 [00:00<00:00, 11298.51it/s]\n",
            " 64%|██████▍   | 3200/5000 [00:00<00:00, 11688.82it/s]\n",
            " 66%|██████▌   | 3300/5000 [00:00<00:00, 13608.18it/s]\n",
            " 68%|██████▊   | 3400/5000 [00:00<00:00, 18616.70it/s]\n",
            " 70%|███████   | 3500/5000 [00:00<00:00, 23473.42it/s]\n",
            " 72%|███████▏  | 3600/5000 [00:00<00:00, 13038.08it/s]\n",
            " 74%|███████▍  | 3700/5000 [00:00<00:00, 16668.61it/s]\n",
            " 76%|███████▌  | 3800/5000 [00:00<00:00, 13312.54it/s]\n",
            " 78%|███████▊  | 3900/5000 [00:00<00:00, 14676.58it/s]\n",
            " 80%|████████  | 4000/5000 [00:00<00:00, 11628.09it/s]\n",
            " 82%|████████▏ | 4100/5000 [00:00<00:00, 13760.32it/s]\n",
            " 84%|████████▍ | 4200/5000 [00:00<00:00, 28785.62it/s]\n",
            " 86%|████████▌ | 4300/5000 [00:00<00:00, 15982.55it/s]\n",
            " 88%|████████▊ | 4400/5000 [00:00<00:00, 14866.97it/s]\n",
            " 90%|█████████ | 4500/5000 [00:00<00:00, 12155.48it/s]\n",
            " 92%|█████████▏| 4600/5000 [00:00<00:00, 29332.05it/s]\n",
            " 94%|█████████▍| 4700/5000 [00:00<00:00, 22676.09it/s]\n",
            " 96%|█████████▌| 4800/5000 [00:00<00:00, 16737.58it/s]\n",
            " 98%|█████████▊| 4900/5000 [00:00<00:00, 15304.02it/s]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from itertools import product\n",
        "import torch\n",
        "import collections\n",
        "# Based on original TADA software (He et al. 2013) and rewrite (Klei 2015)\n",
        "\n",
        "# Set seed for reproducibility\n",
        "np.random.seed(100)\n",
        "\n",
        "def TADA(tada_counts, sample_counts, mu, hyperpar, denovo_only, mu_frac=1, pi_gene=1):\n",
        "    # Genome-wide application of TADA for K classes of variants\n",
        "    # tada_counts: Dictionary of K data frames, each consisting of vectors for counts for denovo, case, and control mutation counts\n",
        "    # sample_counts: Dictionary of K data frames, each consisting of a vector with three entries of total sample counts,\n",
        "    #                 one for denovo (# trios), cases (# cases + # trios), and controls (# controls + # trios)\n",
        "    # mu: Data frame with K vectors of mutation rates, one for each mutation category\n",
        "    # mu_frac: Data frame with the fraction to use for each mutation category K\n",
        "    # hyperpar: Dictionary of K data frames, each consisting of entries for gamma.mean.dn, beta.dn, gamma.mean.CC, beta.CC, rho1, nu1, rho0, nu0\n",
        "    # denovo_only: Data frame with K Boolean variables indicating whether only denovo counts should be used (T) or whether both denovo and case-control counts be used (F)\n",
        "    # pi_gene: Data frame with K vectors of estimated fractions of causal variants, one for each class of variants. These fractions will be used to set gene-specific RR (case-control)\n",
        "    # Output: Data frame with BF for each of the K classes of variants as well as BF.total. One entry for each of the genes.\n",
        "\n",
        "    # Make sure every list and dataframe has the same elements\n",
        "    print(\"CALCULATION OF TADA TEST STATISTICS\")\n",
        "    print(\"checking the input for consistent variable names\")\n",
        "    mutation_types = list(tada_counts.keys())\n",
        "    n_mutation = len(mutation_types)\n",
        "    n_samples = len(list(tada_counts.values())[0])\n",
        "\n",
        "    # Make sure mu_frac and pi_gene are data frames\n",
        "    if not isinstance(mu_frac, pd.DataFrame):\n",
        "        mu_frac = pd.DataFrame(np.reshape([[mu_frac] * n_mutation],(1,n_mutation)), columns=mutation_types)\n",
        "\n",
        "    if not isinstance(pi_gene, pd.DataFrame):\n",
        "        pi_gene = pd.DataFrame(np.reshape([[pi_gene] * n_mutation * n_samples],(n_samples,n_mutation,)), columns=mutation_types)\n",
        "\n",
        "    if (\n",
        "        sum([mutation_type in mu for mutation_type in mutation_types]) != n_mutation\n",
        "        or sum([mutation_type in mu_frac for mutation_type in mutation_types]) != n_mutation\n",
        "        or sum([mutation_type in hyperpar for mutation_type in mutation_types]) != n_mutation\n",
        "        or sum([mutation_type in pi_gene for mutation_type in mutation_types]) != n_mutation\n",
        "        or sum([mutation_type in denovo_only for mutation_type in mutation_types]) != n_mutation\n",
        "        or sum([mutation_type in sample_counts for mutation_type in mutation_types]) != n_mutation\n",
        "    ):\n",
        "        return \"mismatch in names for the different variables\"\n",
        "    names_trans_categories = list(sample_counts.keys())\n",
        "    names_N = ['dn', 'ca', 'cn']\n",
        "\n",
        "    for mutation in mutation_types:\n",
        "        if sum(names_N[i] in tada_counts[mutation] for i in range(3)) != 3:\n",
        "            return f\"columns of {mutation} do not match the required 'dn' 'ca' 'cn'\"\n",
        "\n",
        "    # Find the number of genes and the number of different kinds of mutations\n",
        "    n_gene = len(mu)  # was m\n",
        "    n_mutation = len(mutation_types)  # was K\n",
        "\n",
        "    BF = pd.DataFrame()\n",
        "    for mutation in mutation_types:\n",
        "        print(f\"working on :: {mutation}\")\n",
        "        BF_mut = np.array([])\n",
        "        for i in range(len(tada_counts[mutation])):\n",
        "            test_BF = calculate_BF(i,tada_counts[mutation], sample_counts[mutation], mu[mutation], mu_frac[mutation],\n",
        "                             hyperpar[mutation], denovo_only[mutation].item(), pi_gene[mutation])\n",
        "            BF_mut = np.append(BF_mut,test_BF[0])\n",
        "\n",
        "        BF = pd.concat([BF, pd.DataFrame(BF_mut)], axis=1)\n",
        "    BF.columns = mutation_types\n",
        "    BF.index = tada_counts[mutation].index\n",
        "\n",
        "    # Calculate the overall BF\n",
        "    BF_total = np.exp(np.log(BF).sum(axis=1))\n",
        "\n",
        "    return {'BF': BF, 'BF.total': BF_total}\n",
        "\n",
        "def TADAnull(tada_counts, sample_counts, mu, hyperpar, denovo_only, mu_frac=1, n_rep=100, dn_max=20, ca_max=200, cn_max=200, max_gap=50):\n",
        "    print(\"CALCULATION OF TADA TEST STATISTICS UNDER THE NULL HYPOTHESIS\")\n",
        "    mutations = list(hyperpar.keys())\n",
        "    n_mutation = len(mutations)\n",
        "    n_samples = len(list(tada_counts.values())[0])\n",
        "\n",
        "    if not isinstance(mu_frac, pd.DataFrame):\n",
        "        mu_frac = pd.DataFrame(np.reshape([[mu_frac] * n_mutation * n_samples],(n_samples,n_mutation)), columns=mutations)\n",
        "\n",
        "    #Pre-compute the bayes factors for the denovo data\n",
        "    table_BF_dn = {}\n",
        "    for mutation in mutations:\n",
        "        print(f\"working on creating DN table for :: {mutation}\")\n",
        "        x = np.arange(dn_max + 1)\n",
        "        param = hyperpar[mutation]\n",
        "        n = sample_counts[mutation][\"dn\"]\n",
        "\n",
        "        BF = table_BF_dn_wrapper(x, n, mu[mutation] * mu_frac[mutation], param[\"gamma.mean.dn\"], param[\"beta.dn\"])\n",
        "        table_BF_dn[mutation] = pd.DataFrame(BF, columns=[f\"X{value}\" for value in x])\n",
        "\n",
        "    table_BF_cc = {}\n",
        "    for mutation in mutations:\n",
        "        if not denovo_only[mutation].item():\n",
        "            print(f\"working on creating CC table for :: {mutation}\")\n",
        "            tada_counts[mutation][\"Ncc\"] = tada_counts[mutation][[\"ca\", \"cn\"]].sum(axis=1)\n",
        "            Ncc = sorted(tada_counts[mutation][\"Ncc\"])\n",
        "            Ncc_gaps = np.diff(Ncc)\n",
        "            i_gap = np.argmax(Ncc_gaps > max_gap)\n",
        "            n_ca = min(ca_max, Ncc[i_gap])\n",
        "            n_cn = min(cn_max, Ncc[i_gap])\n",
        "            x = pd.DataFrame(list(product(range(n_ca + 1), range(n_cn + 1))), columns=[\"ca\", \"cn\"])\n",
        "            param = hyperpar[mutation]\n",
        "            n = sample_counts[mutation][[\"ca\", \"cn\"]]\n",
        "\n",
        "            BF = table_BF_cc_wrapper(\n",
        "                x,\n",
        "                n,\n",
        "                param[\"gamma.mean.CC\"],\n",
        "                param[\"beta.CC\"],\n",
        "                param[\"rho1\"],\n",
        "                param[\"nu1\"],\n",
        "                param[\"rho0\"],\n",
        "                param[\"nu0\"],\n",
        "            )\n",
        "            table_BF_cc[mutation] = BF.values.reshape(n_ca + 1, n_cn + 1)\n",
        "\n",
        "    return {\"table.BF.dn\": table_BF_dn, \"table.BF.cc\": table_BF_cc}\n",
        "\n",
        "\n",
        "def calculate_BF(i_gene, counts, n, mu, mu_frac, hyperpar, denovo_only, pi_gene):\n",
        "    # Wrapper so that lapply can be used to determine the BF for a gene and a particular mutation variant\n",
        "    # i_gene: gene of interest\n",
        "    # counts: counts for a particular variant, dataframe with vectors for dn, ca, cn\n",
        "    # n: total samples counts, dataframe with entries for dn, ca, cn\n",
        "    # mu: vector with mutation rates for the variant of interest for each gene\n",
        "    # mu_frac: fraction to multiply mu with for the variant of interest\n",
        "    # hyperpar: dataframe with entries for gamma.mean.dn, beta.dn, gamma.mean.CC, beta.CC, rho1, nu1, rho0, nu0 for the\n",
        "    #           variant of interest\n",
        "    # denovo_only: Boolean vector indicating whether only denovo contribution (denovo_only = True) or a combination of\n",
        "    #              denovo and case-control contributions is to be used (denovo_only=False)\n",
        "    # pi_gene: vector with K vectors of estimated fractions of causal variants, one for each class of variants.\n",
        "    #          These fractions will be used to set gene-specific RR (case-control)\n",
        "\n",
        "    if i_gene % 100 == 0 or i_gene == len(counts):\n",
        "        pbar = tqdm(total=len(counts))\n",
        "\n",
        "    ### set the hyper parameters for this gene\n",
        "    hyperpar_gene = hyperpar.copy()\n",
        "    RR_product = hyperpar_gene['gamma.mean.CC'] * hyperpar_gene['beta.CC']\n",
        "    hyperpar_gene['gamma.mean.CC'] = hyperpar_gene['gamma.mean.CC'] * pi_gene[i_gene] + (1 - pi_gene[i_gene])\n",
        "    hyperpar_gene['beta.CC'] = RR_product / hyperpar_gene['gamma.mean.CC']\n",
        "    # Determine the BAYES factor\n",
        "    BF = bayes_factor(x=counts.iloc[i_gene, :], n=n, mu=mu[i_gene] * mu_frac, param=hyperpar_gene, denovo_only=denovo_only)\n",
        "\n",
        "    if i_gene % 100 == 0 or i_gene == len(counts):\n",
        "        pbar.update(i_gene)\n",
        "        pbar.close()\n",
        "\n",
        "    return BF\n",
        "\n",
        "def bayes_factor(x, n, mu, param, denovo_only):\n",
        "    # Bayes factor of the gene combining de novo and case-control\n",
        "    # x: a list of (dn, ca, cn), counts in de novo, cases and controls\n",
        "    # n: a list of (dn, ca, cn), sample sizes\n",
        "    # param: (gamma.mean.dn, beta.dn, gamma.mean.CC, beta.CC, rho1, nu1, rho0, nu0)\n",
        "    # denovo_only: Boolean indicating whether only denovo contribution (True) or a combination of\n",
        "    #              denovo and case-control contributions is to be used (False)\n",
        "    # Prior distribution of RR in de novo: gamma.dist.dn ~ Gamma(gamma.mean.dn * beta.dn, beta.dn)\n",
        "    # Prior distribution of RR in C/C data: gamma.dist.cc ~ Gamma(gamma.mean.CC * beta.CC, beta.CC)\n",
        "    # Prior distribution of q|H1: Gamma(rho1, nu1)\n",
        "    # Prior distribution of q|H0: Gamma(rho0, nu0)\n",
        "\n",
        "    # Contribution of denovo variants in families\n",
        "    BF_dn = bayes_factor_dn(x_dn=x['dn'], n_dn=n['dn'], mu=mu, gamma_dn=param['gamma.mean.dn'], beta_dn=param['beta.dn'])\n",
        "    if not denovo_only:\n",
        "        # Contribution of variants in cases and controls\n",
        "        BF_cc = bayes_factor_cc(x_cc=x[['ca', 'cn']], n_cc=n[['ca', 'cn']], gamma_cc=param['gamma.mean.CC'], beta_cc=param['beta.CC'],\n",
        "                                rho1=param['rho1'], nu1=param['nu1'], rho0=param['rho0'], nu0=param['nu0'])\n",
        "    else:\n",
        "        BF_cc = 1\n",
        "    # Combine the pieces of information\n",
        "    BF = BF_dn * BF_cc\n",
        "    return BF\n",
        "\n",
        "def bayes_factor_dn(x_dn, n_dn, mu, gamma_dn, beta_dn):\n",
        "    # Bayes factor of de novo counts of a gene\n",
        "    # x_dn: the de novo count\n",
        "    # n_dn: the sample size (number of families)\n",
        "    # mu: the mutation rate (of this type of mutational events)\n",
        "    # Prior distribution of RR: gamma ~ Gamma(gamma_dn * beta_dn, beta_dn)\n",
        "    marg_lik0 = poisson.pmf(x_dn, 2 * n_dn * mu)\n",
        "    marg_lik1 = nbinom.pmf(x_dn, gamma_dn * beta_dn, beta_dn / (beta_dn + 2 * n_dn * mu))\n",
        "    BF = marg_lik1 / marg_lik0\n",
        "    return BF\n",
        "\n",
        "\n",
        "def bayes_factor_cc(x_cc, n_cc, gamma_cc, beta_cc, rho1, nu1, rho0, nu0):\n",
        "    # Bayes factor of the case-control data\n",
        "    # BF_cn and BF_ca: contribution from control and case data, respectively\n",
        "    # Input: the count data x_cc, the sample size n_cc and the parameters gamma_cc, beta_cc, rho1 and nu1\n",
        "    # Prior distribution of RR: gamma ~ Gamma(gamma_cc * beta_cc, beta_cc)\n",
        "    # Prior distribution of q|H1: Gamma(rho1, nu1)\n",
        "    # Prior distribution of q|H0: Gamma(rho0, nu0)\n",
        "    marglik0_cc = evidence_null_cc(x_cc, n_cc, rho0, nu0)\n",
        "    marglik1_cc = evidence_alt_cc(x_cc, n_cc, gamma_cc, beta_cc, rho1, nu1)\n",
        "    BF_cn = marglik1_cc[\"cn\"] / marglik0_cc[\"cn\"]\n",
        "    BF_ca = marglik1_cc[\"ca\"] / marglik0_cc[\"ca\"]\n",
        "    BF = BF_cn * BF_ca\n",
        "    return BF\n",
        "\n",
        "def evidence_null_cc(x_cc, n_cc, rho0, nu0):\n",
        "    # model evidence of case-control data: P(x_1,x_0|H_0)\n",
        "    # Input: the count data x_cc, the sample size n_cc, and the rho0 and nu0\n",
        "    # Prior distribution of q|H0: Gamma(rho0, nu0)\n",
        "    marglik0_ctrl_log = np.log(nbinom.pmf(x_cc[\"cn\"], rho0, nu0 / (nu0 + n_cc[\"cn\"])))\n",
        "    marglik0_case_log = np.log(nbinom.pmf(x_cc[\"ca\"], rho0 + x_cc[\"cn\"], (nu0 + n_cc[\"cn\"]) / (nu0 + n_cc[\"cn\"] + n_cc[\"ca\"])))\n",
        "    marglik0_log = marglik0_ctrl_log + marglik0_case_log\n",
        "\n",
        "    return {\"cn\": np.exp(marglik0_ctrl_log), \"ca\": np.exp(marglik0_case_log), \"total\": np.exp(marglik0_log)}\n",
        "\n",
        "def evidence_alt_cc(x_cc, n_cc, gamma_cc, beta_cc, rho1, nu1, q_lower=1e-8, q_upper=0.1, debug=False):\n",
        "    # model evidence of case-control data: P(x_1,x_0|H_1)\n",
        "    # Input: the count data x_cc, the sample size n_cc, and the parameters gamma_cc, beta_cc, rho1, and nu1\n",
        "    # Prior distribution of RR: gamma ~ Gamma(gamma_cc*beta_cc, bet a_cc)\n",
        "    # Prior distribution of q|H1: Gamma(rho1, nu1)\n",
        "    def integrand(u):\n",
        "        q = np.exp(u)\n",
        "        return (nbinom.pmf(x_cc[\"ca\"], gamma_cc * beta_cc, beta_cc / (beta_cc + n_cc[\"ca\"] * q)) *\n",
        "                gamma.pdf(q, rho1 + x_cc[\"cn\"], scale=1 / (nu1 + n_cc[\"cn\"])) * np.exp(u))\n",
        "\n",
        "    marglik1_ctrl = nbinom.pmf(x_cc[\"cn\"], rho1, nu1 / (nu1 + n_cc[\"cn\"]))\n",
        "    marglik1_case = integrate.quad(integrand, np.log(q_lower), np.log(q_upper))[0]\n",
        "\n",
        "    marglik1 = marglik1_ctrl * marglik1_case\n",
        "\n",
        "    return {\"cn\": marglik1_ctrl, \"ca\": marglik1_case, \"total\": marglik1}\n",
        "def table_BF_dn_wrapper(i_x, x, n_dn, mu, gamma_dn, beta_dn):\n",
        "    # a wrapper function used for generating the denovo table, see bayes.factor.dn for a description of the variables\n",
        "    BF = bayes_factor_dn(x[i_x], n_dn=n_dn, mu=mu, gamma_dn=gamma_dn, beta_dn=beta_dn)\n",
        "    return BF\n",
        "\n",
        "\n",
        "def table_BF_cc_wrapper(i_x, x, n_cc, gamma_cc, beta_cc, rho1, nu1, rho0, nu0):\n",
        "    # a wrapper function used for generating the case-control table, see bayes.factor.cc for a description of the variables\n",
        "    if (i_x % 100 == 0 or i_x == len(x)) and len(x) > 1000:\n",
        "        pb = tqdm(total=len(x))\n",
        "        pb.update(i_x)\n",
        "    BF = bayes_factor_cc(x[i_x], n_cc=n_cc, gamma_cc=gamma_cc, beta_cc=beta_cc, rho1=rho1, nu1=nu1, rho0=rho0, nu0=nu0)\n",
        "    return BF\n",
        "\n",
        "def permute_gene(i_gene, mu_rate, counts, n, n_rep, param, denovo_only, table_cc, table_dn):\n",
        "    # Compute permutation BFs of one gene\n",
        "    # mu_rate: the mutation rate of a gene for the variant of interest\n",
        "    # counts: dn, ca, and co counts for the variant of interest to be permuted, this also has a column for Ncc=ca+cn\n",
        "    # n: sample size, for values for de novo, case, control, and case+control\n",
        "    # n_rep: number of permutations\n",
        "    # param: set of hyper parameters for the variant of interest.\n",
        "    # table_cc: table of precomputed BFs for case control events of size max.ca by max.cn for the variant of interest\n",
        "    # table_dn: table of precomputed BFs for denovo events of size number of genes by max.dn for the variant of interest\n",
        "    # Output: vector of n_rep BF generated under the null hypothesis\n",
        "\n",
        "    if i_gene % 100 == 0 or i_gene == counts.shape[0]:\n",
        "        print(f\"Progress: {i_gene}/{counts.shape[0]}\")\n",
        "\n",
        "    # generate permutation data for denovo events\n",
        "    sample_dn = np.random.poisson(2 * n_rep * mu_rate[i_gene], size=n_rep)\n",
        "    # look up the BF value in the table\n",
        "    print(\"Tabcc,table_cc\")\n",
        "    print(\"tab\",table_dn)\n",
        "    print(\"i\",i_gene)\n",
        "    print(\"samp\",sample_dn)\n",
        "    BF_dn = table_dn[i_gene, sample_dn]\n",
        "\n",
        "    if not denovo_only:\n",
        "        # when both denovo and case-control BF are needed\n",
        "        # generate permutation data for case-control events\n",
        "        max_ca = table_cc.shape[0]\n",
        "        max_cn = table_cc.shape[1]\n",
        "        sample_ca = np.zeros(n_rep)\n",
        "        sample_cn = np.zeros(n_rep)\n",
        "\n",
        "        for j in range(n_rep):\n",
        "            sample_ca[j] = np.random.hypergeometric(counts[\"Ncc\"][i_gene], n[\"ca\"] + n[\"cn\"] - counts[\"Ncc\"][i_gene], n[\"ca\"])\n",
        "            sample_cn[j] = counts[\"Ncc\"][i_gene] - sample_ca[j]\n",
        "\n",
        "        # find the generated counts that are outside of the pre-computed table\n",
        "        i_na = np.where((sample_ca + 1 > max_ca) | (sample_cn + 1 > max_cn))[0]\n",
        "        if len(i_na) > 0:\n",
        "            # calculate their BF on a case by case basis\n",
        "            BF_na = np.zeros(len(i_na))\n",
        "            for idx, i in enumerate(i_na):\n",
        "                BF_na[idx] = table_BF_cc_wrapper(data={\"ca\": sample_ca[i], \"cn\": sample_cn[i]},\n",
        "                                                 n_cc=n[[\"ca\", \"cn\"]],\n",
        "                                                 gamma_cc=param[\"gamma.mean.CC\"],\n",
        "                                                 beta_cc=param[\"beta.CC\"],\n",
        "                                                 rho1=param[\"rho1\"],\n",
        "                                                 nu1=param[\"nu1\"],\n",
        "                                                 rho0=param[\"rho0\"],\n",
        "                                                 nu0=param[\"nu0\"])\n",
        "\n",
        "        # set the counts outside the range to missing\n",
        "        sample_ca[sample_ca + 1 > max_ca] = np.nan\n",
        "        sample_cn[sample_cn + 1 > max_cn] = np.nan\n",
        "\n",
        "        # gather the BF values that can be taken from the pre-computed table\n",
        "        BF_cc = table_cc[sample_ca + 1, sample_cn + 1]\n",
        "\n",
        "        # replace the missing values with the pre-computed ones\n",
        "        i_na = np.where(np.isnan(BF_cc))[0]\n",
        "        if len(i_na) > 0:\n",
        "            BF_cc[i_na] = BF_na\n",
        "\n",
        "    else:\n",
        "        # if denovo only needed then set BF_dn to 1\n",
        "        BF_cc = np.ones(n_rep)\n",
        "\n",
        "    # determine the total BF from the two components\n",
        "    BF = BF_cc * BF_dn\n",
        "\n",
        "    return BF\n",
        "\n",
        "def Bayesian_FDR(BF, pi0):\n",
        "    # Bayesian FDR control (PMID:19822692, Section2.3)\n",
        "    # BF: a vector of BFs\n",
        "    # pi0: the prior probability that the null model is true\n",
        "    # Return: the q-value of each BF, and the number of findings with q below alpha.\n",
        "\n",
        "    # order the BF in decreasing order, need to retain order to get results back in proper order\n",
        "    i_order = np.argsort(-BF)\n",
        "    BF = BF[i_order]\n",
        "\n",
        "    # convert BFs to PPA (posterior probability of alternative model)\n",
        "    pi = 1 - pi0\n",
        "    q = pi * BF / (1 - pi + pi * BF)  # PPA\n",
        "    q0 = 1 - q  # posterior probability of null model\n",
        "\n",
        "    # the FDR at each PPA cutoff\n",
        "    FDR = np.cumsum(q0) / np.arange(1, len(BF) + 1)\n",
        "\n",
        "    # reorder to the original order\n",
        "    FDR[i_order] = FDR\n",
        "\n",
        "    return FDR\n",
        "\n",
        "def bayesFactor_pvalue(BF, BF_null):\n",
        "    # determines the p-value for the BF using permutations under the null hypothesis BF_null\n",
        "    # BF: vector with bayes factors based on the data\n",
        "    # BF_null: vector with bayes factors based on permuted data\n",
        "\n",
        "    BF_null = np.sort(BF_null)[::-1]\n",
        "    pval = np.searchsorted(-BF_null, -BF) / len(BF_null)\n",
        "    pval[pval == 0] = 0.5 / len(BF_null)\n",
        "\n",
        "    return pval\n",
        "\n",
        "def denovo_MOM(k, N, mu, C, beta, d=2, S=100, max_kvec=None):\n",
        "    # Estimating relative risk and the number of multiple hits from de novo data\n",
        "    # Input:  k - number of disease genes\n",
        "    #         N - sample size\n",
        "    #         mu - mutation rate for all genes\n",
        "    #         C - observed number of de novo events\n",
        "    #         beta - parameter of the prior distribution of gamma\n",
        "    #         d - number of events to use (1 is 1 or more, 2 is 2 or more)\n",
        "    #         S - number of samples to generate per gene\n",
        "    #         max_kvec - used to generate a time line.\n",
        "    # Output: gamma_mean - the average relative risk,\n",
        "    #         M - the expected number of multi-hit genes\n",
        "\n",
        "    if max_kvec is not None:\n",
        "        if k % 100 == 0 or k == max_kvec:\n",
        "            pb = tqdm(total=max_kvec)\n",
        "            pb.update(k)\n",
        "\n",
        "    m = len(mu)  # number of genes\n",
        "\n",
        "    # enrichment of de novo events\n",
        "    nu = C / (2 * N * np.sum(mu))\n",
        "\n",
        "    # MOM estimator of gamma_mean\n",
        "    gamma_mean = (nu - 1) * m / k + 1\n",
        "\n",
        "    # expected M (choose d = 2)\n",
        "    rs = count_multihit(N, mu, k / m, gamma_mean, beta, d=d, S=S)\n",
        "    M = np.sum(rs['M1']) + np.sum(rs['M0'])\n",
        "\n",
        "    return {'gamma.mean': gamma_mean, 'M': M}\n",
        "\n",
        "\n",
        "def count_multihit(N, mu, pi, gamma_mean, beta, d, S):\n",
        "    # Estimate the number of multihit genes in a genome.\n",
        "    # N: sample size\n",
        "    # mu: mutation rate for all genes\n",
        "    # pi: ratio of number of risk genes and total number of genes\n",
        "    # gamma_mean: the average relative risk\n",
        "    # beta: parameter of the prior distribution of gamma\n",
        "    # d: number of events to use (1 is 1 or more, 2 is 2 or more)\n",
        "    # S: number of samples to generate per gene\n",
        "    # Output: M0 - number of multiple-hit genes for the non-risk genes\n",
        "    #         M1 - number of multiple-hit genes for risk genes\n",
        "\n",
        "    m = len(mu)\n",
        "\n",
        "    # M1: the number of causal genes having d or more de novo mutations\n",
        "    p_alt = np.column_stack([multihit_prob(mu_i, N, gamma_mean, beta, d=d, S=S) for mu_i in mu])\n",
        "    M1 = m * pi * np.mean(p_alt, axis=0)\n",
        "\n",
        "    # M0: the number of non-causal genes having d or more de novo mutations\n",
        "    p_null = np.column_stack([(1 - poisson.cdf(d_i, 2 * N * mu_i)) for mu_i in mu for d_i in d])\n",
        "    p_null = p_null.reshape(m, len(d))\n",
        "    M0 = m * (1 - pi) * np.mean(p_null, axis=0)\n",
        "\n",
        "    result = pd.DataFrame({'d': d, 'M0': M0, 'M1': M1})\n",
        "    return result\n",
        "\n",
        "def multihit_prob(mu, N, gamma_mean, beta, d, S):\n",
        "    # Prob. of having d or more de novo mutations under H1\n",
        "    # Use simulation, but could also use analytic form\n",
        "    # mu: mutation rate for a gene\n",
        "    # N: sample size\n",
        "    # gamma_mean: the average relative risk\n",
        "    # beta: parameter of the prior distribution of gamma\n",
        "    # d: number of events to use (1 is 1 or more, 2 is 2 or more)\n",
        "    # S: number of samples to generate per gene\n",
        "    # Output: p - average probability of having d or more de novo mutations\n",
        "\n",
        "    gamma = gamma.rvs(gamma_mean * beta, scale=1 / beta, size=S)\n",
        "    p = 1 - poisson.cdf(d, 2 * N * mu * gamma)\n",
        "    return np.mean(p)\n",
        "\n",
        "# Read mutation data\n",
        "tada_file = \"TADA_demo_counts_de-novo_and_inherited.txt\"\n",
        "tada_data = pd.read_table(tada_file)\n",
        "\n",
        "# Specify the number of families and the number of cases and control samples included in the analysis\n",
        "n_family = 4500\n",
        "n_case = 1000\n",
        "n_ctrl = 3000\n",
        "\n",
        "data = {'dn': [n_family], 'ca': [n_case + n_family], 'cn': [n_ctrl + n_family]}\n",
        "n = pd.DataFrame(data)\n",
        "sample_counts = {'cls1': n, 'cls2': n}\n",
        "\n",
        "# Create the mutational data used by TADA\n",
        "cls1_counts = pd.DataFrame({'dn': tada_data['dn.cls1'],\n",
        "                            'ca': tada_data['trans.cls1'] + tada_data['case.cls1'],\n",
        "                            'cn': tada_data['ntrans.cls1'] + tada_data['ctrl.cls1']})\n",
        "cls1_counts.index = tada_data['gene.id']\n",
        "\n",
        "cls2_counts = pd.DataFrame({'dn': tada_data['dn.cls2'],\n",
        "                            'ca': tada_data['trans.cls2'] + tada_data['case.cls2'],\n",
        "                            'cn': tada_data['ntrans.cls2'] + tada_data['ctrl.cls2']})\n",
        "cls2_counts.index = tada_data['gene.id']\n",
        "\n",
        "tada_counts = {'cls1': cls1_counts, 'cls2': cls2_counts}\n",
        "\n",
        "# Set up mutation rates\n",
        "mu = pd.DataFrame({'cls1': tada_data['mut.cls1'], 'cls2': tada_data['mut.cls2']})\n",
        "\n",
        "# Set up denovo only TRUE/FALSE, here we do not want to restrict ourselves to de novo only analyses\n",
        "denovo_only = pd.DataFrame({'cls1': [False], 'cls2': [False]})\n",
        "\n",
        "# Set up parameters\n",
        "cls1_params = pd.DataFrame({'gamma.mean.dn': [20.0],\n",
        "                            'beta.dn': [1],\n",
        "                            'gamma.mean.CC': [2.3],\n",
        "                            'beta.CC': [4.0],\n",
        "                            'rho1': [0.1],\n",
        "                            'nu1': [100],\n",
        "                            'rho0': [0.1],\n",
        "                            'nu0': [100]})\n",
        "\n",
        "cls2_params = pd.DataFrame({'gamma.mean.dn': [4.7],\n",
        "                            'beta.dn': [1],\n",
        "                            'gamma.mean.CC': [1.0],\n",
        "                            'beta.CC': [1000],\n",
        "                            'rho1': [0.15],\n",
        "                            'nu1': [100],\n",
        "                            'rho0': [0.15],\n",
        "                            'nu0': [100]})\n",
        "\n",
        "hyperpar = {'cls1': cls1_params, 'cls2': cls2_params}\n",
        "# Running TADA\n",
        "re_TADA = TADA(tada_counts=tada_counts, sample_counts=sample_counts, mu=mu, hyperpar=hyperpar, denovo_only=denovo_only)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def TADAnull(tada_counts, sample_counts, mu, hyperpar, denovo_only, mu_frac=1, n_rep=100, dn_max=20, ca_max=200, cn_max=200, max_gap=50):\n",
        "    # Genome-wide application of TADA for K classes of variants\n",
        "    # This function determines the distribution of the null hypothesis test statistics which in turn can be used to determine approximate p-values\n",
        "    # tada.counts: list of K data frames in which each dataframe consists of vectors for counts for denovo, case and control mutation counts\n",
        "    # sample.counts: list of K data frames in which each dataframe consists of a vector with three entries of total sample counts,\n",
        "    #                 one for denovo (# trios), cases (# cases + # trios) and controls (# controls + # trios)\n",
        "    # mu: data frame with K vectors of mutation rates. One for each mutation category.\n",
        "    # mu.frac: data frame with the fraction to use for each mutation category K\n",
        "    # hyperpar: list of K data frames. Each data frame consists of entries for gamma.mean.dn, beta.dn, gamma.mean.CC, beta.CC, rho1, nu1, rho0, nu0\n",
        "    # denovo.only: data frame with K Boolean variables of indicating whether only denovo counts should be used (T) or whether both denovo and case-control\n",
        "    # counts be used (F).\n",
        "    # n_rep: number of repetitions to use recommended to be at least 100. For smaller numbers of genes n_rep should be increased.\n",
        "    # dn.max: number of denovo events for which the BF is pre-computed and stored in a table. This speeds up the simulation process. The function will use dn.max or\n",
        "    #         the maximum number of denovo events for a gene, whichever is smaller.\n",
        "    # ca.max and cn.max: as dn.max this is used to pre-compute a table of common case-control count events to speed up processing. The larger these numbers, the longer the\n",
        "    #                     the longer the pre computation step takes. For very large values of ca.max and cn.max an intergration error might occur.\n",
        "    # max.gap: this is used internally to control the size of the pre-compution of the case-control BF matrix. It represents the gap between two genes in\n",
        "    #           case-control count when ordered from smallest to largest count. This essentially identifies outlying values that hardly ever happen and do not have to be\n",
        "    #           pre-computed.\n",
        "    # Output: dataframe with BFnull for each of the K classes of variants as well as BFnull.total. One entry for each of the genes times n_rep.\n",
        "\n",
        "    print(\"CALCULATION OF TADA TEST STATISTICS UNDER THE NULL HYPOTHESIS\")\n",
        "    mutations = list(hyperpar.keys())\n",
        "    n_mutation = len(mutations)\n",
        "    n_samples = len(list(tada_counts.values())[0])\n",
        "\n",
        "    if not isinstance(mu_frac, pd.DataFrame):\n",
        "        mu_frac = pd.DataFrame(np.reshape([[mu_frac] * n_mutation * n_samples],(n_samples,n_mutation)), columns=mutations)\n",
        "\n",
        "    #Pre-compute the bayes factors for the denovo data\n",
        "    table_BF_dn = {}\n",
        "    for mutation in mutations:\n",
        "        print(f\"working on creating DN table for :: {mutation}\")\n",
        "        x = np.arange(dn_max + 1)\n",
        "        param = hyperpar[mutation]\n",
        "        n = sample_counts[mutation]\n",
        "        BF = np.array([])\n",
        "        for i in range(len(x)):\n",
        "            BF_i = bayes_factor_dn(x[i], n_dn=n, mu=mu[mutation] * mu_frac[mutation], gamma_dn=param[\"gamma.mean.dn\"], beta_dn=param[\"beta.dn\"])\n",
        "            BF = np.append(BF,BF_i)\n",
        "            print(BF_i,BF)\n",
        "        table_BF_dn[mutation] = pd.DataFrame(np.reshape(BF,(len(BF)//len(x),len(x))), columns=[f\"X{value}\" for value in x])\n",
        "\n",
        "    table_BF_cc = {}\n",
        "    for mutation in mutations:\n",
        "        if not denovo_only[mutation].item():\n",
        "            print(f\"working on creating CC table for :: {mutation}\")\n",
        "            tada_counts[mutation][\"Ncc\"] = tada_counts[mutation][[\"ca\", \"cn\"]].sum(axis=1)\n",
        "            Ncc = sorted(tada_counts[mutation][\"Ncc\"])\n",
        "            Ncc_gaps = np.diff(Ncc)\n",
        "            i_gap = np.argmax(Ncc_gaps > max_gap)\n",
        "            n_ca = min(ca_max, Ncc[i_gap])\n",
        "            n_cn = min(cn_max, Ncc[i_gap])\n",
        "            x = pd.DataFrame(list(product(range(n_ca + 1), range(n_cn + 1))), columns=[\"ca\", \"cn\"])\n",
        "            param = hyperpar[mutation]\n",
        "            n = sample_counts[mutation][[\"ca\", \"cn\"]]\n",
        "            BF = np.array([])\n",
        "            for i in range(len(x)):\n",
        "                BF_i = bayes_factor_cc(x.iloc[i], n_cc=n, gamma_cc=param[\"gamma.mean.CC\"], beta_cc=param[\"beta.CC\"], rho1=param[\"rho1\"], nu1=param[\"nu1\"], rho0=param[\"rho0\"], nu0=param[\"nu0\"])\n",
        "                BF = np.append(BF,BF_i)\n",
        "            table_BF_cc[mutation] = pd.DataFrame(np.reshape(BF,(n_ca + 1, n_cn + 1)))\n",
        "\n",
        "\n",
        "    BF = np.array([])\n",
        "    for mutation in mutations:\n",
        "        print(\"working on creating null data for ::\", mutation)\n",
        "        BF_col = np.array([])\n",
        "        for i in range(len(tada_counts[mutation])):\n",
        "            BF_col = np.append(BF_col,permute_gene(i,mu_rate=mu[mutation] * mu_frac[mutation], counts=tada_counts[mutation],\n",
        "                                                        n=sample_counts[mutation], n_rep=n_rep, param=hyperpar[mutation],\n",
        "                                                        denovo_only=denovo_only[mutation],\n",
        "                                                        table_cc=table_BF_cc[mutation], table_dn=table_BF_dn[mutation]))\n",
        "\n",
        "        BF = np.column_stack((BF, BF_col))\n",
        "    BF = pd.DataFrame(BF, index = np.arange(len(BF)),columns=mutations)\n",
        "    BF_total = np.exp(np.log(BF).sum(axis=1))\n",
        "\n",
        "    return {'BF_null': BF, 'BF_null.total': BF_total}\n",
        "\n",
        "def bayes_factor_cc(x_cc, n_cc, gamma_cc, beta_cc, rho1, nu1, rho0, nu0):\n",
        "    # Bayes factor of the case-control data\n",
        "    # BF_cn and BF_ca: contribution from control and case data, respectively\n",
        "    # Input: the count data x_cc, the sample size n_cc and the parameters gamma_cc, beta_cc, rho1 and nu1\n",
        "    # Prior distribution of RR: gamma ~ Gamma(gamma_cc * beta_cc, beta_cc)\n",
        "    # Prior distribution of q|H1: Gamma(rho1, nu1)\n",
        "    # Prior distribution of q|H0: Gamma(rho0, nu0)\n",
        "    marglik0_cc = evidence_null_cc(x_cc, n_cc, rho0, nu0)\n",
        "    marglik1_cc = evidence_alt_cc(x_cc, n_cc, gamma_cc, beta_cc, rho1, nu1)\n",
        "    BF_cn = marglik1_cc[\"cn\"] / marglik0_cc[\"cn\"]\n",
        "    BF_ca = marglik1_cc[\"ca\"] / marglik0_cc[\"ca\"]\n",
        "    BF = BF_cn * BF_ca\n",
        "    return BF\n",
        "\n",
        "\n",
        "def table_BF_dn_wrapper(i_x, x, n_dn, mu, gamma_dn, beta_dn):\n",
        "    # a wrapper function used for generating the denovo table, see bayes.factor.dn for a description of the variables\n",
        "    BF = bayes_factor_dn(x[i_x], n_dn=n_dn, mu=mu, gamma_dn=gamma_dn, beta_dn=beta_dn)\n",
        "    return BF\n",
        "\n",
        "\n",
        "def table_BF_cc_wrapper(i_x, x, n_cc, gamma_cc, beta_cc, rho1, nu1, rho0, nu0):\n",
        "    # a wrapper function used for generating the case-control table, see bayes.factor.cc for a description of the variables\n",
        "    if (i_x % 100 == 0 or i_x == len(x)) and len(x) > 1000:\n",
        "        pb = tqdm(total=len(x))\n",
        "        pb.update(i_x)\n",
        "    BF = bayes_factor_cc(x[i_x], n_cc=n_cc, gamma_cc=gamma_cc, beta_cc=beta_cc, rho1=rho1, nu1=nu1, rho0=rho0, nu0=nu0)\n",
        "    return BF\n",
        "\n",
        "# Bayesian FDR control\n",
        "re_TADA['qval'] = Bayesian_FDR(re_TADA['BF.total'], pi0=0.95)\n",
        "\n",
        "# Run permutation to get the null distributions to use for calculating p-values for TADA\n",
        "re_TADA_null = TADAnull(tada_counts=tada_counts, sample_counts=sample_counts, mu=mu, hyperpar=hyperpar, denovo_only=denovo_only, n_rep=100)\n",
        "re_TADA['pval'] = bayesFactor_pvalue(re_TADA['BF.total'], re_TADA_null['BFnull.total'])\n",
        "\n",
        "# Top 10 genes based on BF.total\n",
        "top_10_genes = re_TADA.sort_values(by='BF.total', ascending=False).head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CkeOyC_xx8Bq",
        "outputId": "d836d4ba-5466-4bc6-8cfa-34f6f3585131"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CALCULATION OF TADA TEST STATISTICS UNDER THE NULL HYPOTHESIS\n",
            "working on creating DN table for :: cls1\n",
            "[[nan nan nan ... nan nan nan]] [nan nan nan ... nan nan nan]\n",
            "[[nan nan nan ... nan nan nan]] [nan nan nan ... nan nan nan]\n",
            "[[nan nan nan ... nan nan nan]] [nan nan nan ... nan nan nan]\n",
            "[[nan nan nan ... nan nan nan]] [nan nan nan ... nan nan nan]\n",
            "[[nan nan nan ... nan nan nan]] [nan nan nan ... nan nan nan]\n",
            "[[nan nan nan ... nan nan nan]] [nan nan nan ... nan nan nan]\n",
            "[[nan nan nan ... nan nan nan]] [nan nan nan ... nan nan nan]\n",
            "[[nan nan nan ... nan nan nan]] [nan nan nan ... nan nan nan]\n",
            "[[nan nan nan ... nan nan nan]] [nan nan nan ... nan nan nan]\n",
            "[[nan nan nan ... nan nan nan]] [nan nan nan ... nan nan nan]\n",
            "[[nan nan nan ... nan nan nan]] [nan nan nan ... nan nan nan]\n",
            "[[nan nan nan ... nan nan nan]] [nan nan nan ... nan nan nan]\n",
            "[[nan nan nan ... nan nan nan]] [nan nan nan ... nan nan nan]\n",
            "[[nan nan nan ... nan nan nan]] [nan nan nan ... nan nan nan]\n",
            "[[nan nan nan ... nan nan nan]] [nan nan nan ... nan nan nan]\n",
            "[[nan nan nan ... nan nan nan]] [nan nan nan ... nan nan nan]\n",
            "[[nan nan nan ... nan nan nan]] [nan nan nan ... nan nan nan]\n",
            "[[nan nan nan ... nan nan nan]] [nan nan nan ... nan nan nan]\n",
            "[[nan nan nan ... nan nan nan]] [nan nan nan ... nan nan nan]\n",
            "[[nan nan nan ... nan nan nan]] [nan nan nan ... nan nan nan]\n",
            "[[nan nan nan ... nan nan nan]] [nan nan nan ... nan nan nan]\n",
            "working on creating DN table for :: cls2\n",
            "[[nan nan nan ... nan nan nan]] [nan nan nan ... nan nan nan]\n",
            "[[nan nan nan ... nan nan nan]] [nan nan nan ... nan nan nan]\n",
            "[[nan nan nan ... nan nan nan]] [nan nan nan ... nan nan nan]\n",
            "[[nan nan nan ... nan nan nan]] [nan nan nan ... nan nan nan]\n",
            "[[nan nan nan ... nan nan nan]] [nan nan nan ... nan nan nan]\n",
            "[[nan nan nan ... nan nan nan]] [nan nan nan ... nan nan nan]\n",
            "[[nan nan nan ... nan nan nan]] [nan nan nan ... nan nan nan]\n",
            "[[nan nan nan ... nan nan nan]] [nan nan nan ... nan nan nan]\n",
            "[[nan nan nan ... nan nan nan]] [nan nan nan ... nan nan nan]\n",
            "[[nan nan nan ... nan nan nan]] [nan nan nan ... nan nan nan]\n",
            "[[nan nan nan ... nan nan nan]] [nan nan nan ... nan nan nan]\n",
            "[[nan nan nan ... nan nan nan]] [nan nan nan ... nan nan nan]\n",
            "[[nan nan nan ... nan nan nan]] [nan nan nan ... nan nan nan]\n",
            "[[nan nan nan ... nan nan nan]] [nan nan nan ... nan nan nan]\n",
            "[[nan nan nan ... nan nan nan]] [nan nan nan ... nan nan nan]\n",
            "[[nan nan nan ... nan nan nan]] [nan nan nan ... nan nan nan]\n",
            "[[nan nan nan ... nan nan nan]] [nan nan nan ... nan nan nan]\n",
            "[[nan nan nan ... nan nan nan]] [nan nan nan ... nan nan nan]\n",
            "[[nan nan nan ... nan nan nan]] [nan nan nan ... nan nan nan]\n",
            "[[nan nan nan ... nan nan nan]] [nan nan nan ... nan nan nan]\n",
            "[[nan nan nan ... nan nan nan]] [nan nan nan ... nan nan nan]\n",
            "working on creating CC table for :: cls1\n",
            "working on creating CC table for :: cls2\n",
            "working on creating null data for :: cls1\n",
            "Progress: 0/5000\n",
            "Tabcc,table_cc\n",
            "tab       X0  X1  X2  X3  X4  X5  X6  X7  X8  X9  ...  X11  X12  X13  X14  X15  \\\n",
            "0    NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  ...  NaN  NaN  NaN  NaN  NaN   \n",
            "1    NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  ...  NaN  NaN  NaN  NaN  NaN   \n",
            "2    NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  ...  NaN  NaN  NaN  NaN  NaN   \n",
            "3    NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  ...  NaN  NaN  NaN  NaN  NaN   \n",
            "4    NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  ...  NaN  NaN  NaN  NaN  NaN   \n",
            "...   ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ...  ...  ...  ...  ...   \n",
            "4998 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  ...  NaN  NaN  NaN  NaN  NaN   \n",
            "4999 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  ...  NaN  NaN  NaN  NaN  NaN   \n",
            "5000 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  ...  NaN  NaN  NaN  NaN  NaN   \n",
            "5001 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  ...  NaN  NaN  NaN  NaN  NaN   \n",
            "5002 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  ...  NaN  NaN  NaN  NaN  NaN   \n",
            "\n",
            "      X16  X17  X18  X19  X20  \n",
            "0     NaN  NaN  NaN  NaN  NaN  \n",
            "1     NaN  NaN  NaN  NaN  NaN  \n",
            "2     NaN  NaN  NaN  NaN  NaN  \n",
            "3     NaN  NaN  NaN  NaN  NaN  \n",
            "4     NaN  NaN  NaN  NaN  NaN  \n",
            "...   ...  ...  ...  ...  ...  \n",
            "4998  NaN  NaN  NaN  NaN  NaN  \n",
            "4999  NaN  NaN  NaN  NaN  NaN  \n",
            "5000  NaN  NaN  NaN  NaN  NaN  \n",
            "5001  NaN  NaN  NaN  NaN  NaN  \n",
            "5002  NaN  NaN  NaN  NaN  NaN  \n",
            "\n",
            "[5003 rows x 21 columns]\n",
            "i 0\n",
            "samp [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidIndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3802\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: '(0, array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))' is an invalid key",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-dc9f7e473897>\u001b[0m in \u001b[0;36m<cell line: 113>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;31m# Run permutation to get the null distributions to use for calculating p-values for TADA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m \u001b[0mre_TADA_null\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTADAnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtada_counts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtada_counts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_counts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_counts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperpar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperpar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenovo_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdenovo_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0mre_TADA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pval'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbayesFactor_pvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre_TADA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'BF.total'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mre_TADA_null\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'BFnull.total'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-dc9f7e473897>\u001b[0m in \u001b[0;36mTADAnull\u001b[0;34m(tada_counts, sample_counts, mu, hyperpar, denovo_only, mu_frac, n_rep, dn_max, ca_max, cn_max, max_gap)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mBF_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtada_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmutation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             BF_col = np.append(BF_col,permute_gene(i,mu_rate=mu[mutation] * mu_frac[mutation], counts=tada_counts[mutation],\n\u001b[0m\u001b[1;32m     70\u001b[0m                                                         \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmutation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_rep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperpar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmutation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                                                         \u001b[0mdenovo_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdenovo_only\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmutation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-0c7c7a6a1fe0>\u001b[0m in \u001b[0;36mpermute_gene\u001b[0;34m(i_gene, mu_rate, counts, n, n_rep, param, denovo_only, table_cc, table_dn)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"i\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi_gene\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"samp\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msample_dn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     \u001b[0mBF_dn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtable_dn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_gene\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_dn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdenovo_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3807\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3808\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3809\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3807\u001b[0m                 \u001b[0;31m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3808\u001b[0m                 \u001b[0;31m#  the TypeError.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3809\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_indexing_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3810\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_check_indexing_error\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   5923\u001b[0m             \u001b[0;31m# if key is not a scalar, directly raise an error (the code below\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5924\u001b[0m             \u001b[0;31m# would convert to numpy arrays and raise later any way) - GH29926\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5925\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5927\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcache_readonly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidIndexError\u001b[0m: (0, array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from itertools import product\n",
        "import torch\n",
        "import collections\n",
        "# Based on original TADA software (He et al. 2013) and rewrite (Klei 2015)\n",
        "\n",
        "# Set seed for reproducibility\n",
        "np.random.seed(100)\n",
        "\n",
        "def TADA(tada_counts, sample_counts, mu, hyperpar, denovo_only, mu_frac=1, pi_gene=1):\n",
        "    # Genome-wide application of TADA for K classes of variants\n",
        "    # tada_counts: Dictionary of K data frames, each consisting of vectors for counts for denovo, case, and control mutation counts\n",
        "    # sample_counts: Dictionary of K data frames, each consisting of a vector with three entries of total sample counts,\n",
        "    #                 one for denovo (# trios), cases (# cases + # trios), and controls (# controls + # trios)\n",
        "    # mu: Data frame with K vectors of mutation rates, one for each mutation category\n",
        "    # mu_frac: Data frame with the fraction to use for each mutation category K\n",
        "    # hyperpar: Dictionary of K data frames, each consisting of entries for gamma.mean.dn, beta.dn, gamma.mean.CC, beta.CC, rho1, nu1, rho0, nu0\n",
        "    # denovo_only: Data frame with K Boolean variables indicating whether only denovo counts should be used (T) or whether both denovo and case-control counts be used (F)\n",
        "    # pi_gene: Data frame with K vectors of estimated fractions of causal variants, one for each class of variants. These fractions will be used to set gene-specific RR (case-control)\n",
        "    # Output: Data frame with BF for each of the K classes of variants as well as BF.total. One entry for each of the genes.\n",
        "\n",
        "    # Make sure every list and dataframe has the same elements\n",
        "    print(\"CALCULATION OF TADA TEST STATISTICS\")\n",
        "    print(\"checking the input for consistent variable names\")\n",
        "    mutation_types = list(tada_counts.keys())\n",
        "    n_mutation = len(mutation_types)\n",
        "    n_samples = len(list(tada_counts.values())[0])\n",
        "\n",
        "    # Make sure mu_frac and pi_gene are data frames\n",
        "    if not isinstance(mu_frac, pd.DataFrame):\n",
        "        mu_frac = pd.DataFrame(np.reshape([[mu_frac] * n_mutation],(1,n_mutation)), columns=mutation_types)\n",
        "\n",
        "    if not isinstance(pi_gene, pd.DataFrame):\n",
        "        pi_gene = pd.DataFrame(np.reshape([[pi_gene] * n_mutation * n_samples],(n_samples,n_mutation,)), columns=mutation_types)\n",
        "\n",
        "    if (\n",
        "        sum([mutation_type in mu for mutation_type in mutation_types]) != n_mutation\n",
        "        or sum([mutation_type in mu_frac for mutation_type in mutation_types]) != n_mutation\n",
        "        or sum([mutation_type in hyperpar for mutation_type in mutation_types]) != n_mutation\n",
        "        or sum([mutation_type in pi_gene for mutation_type in mutation_types]) != n_mutation\n",
        "        or sum([mutation_type in denovo_only for mutation_type in mutation_types]) != n_mutation\n",
        "        or sum([mutation_type in sample_counts for mutation_type in mutation_types]) != n_mutation\n",
        "    ):\n",
        "        return \"mismatch in names for the different variables\"\n",
        "    names_trans_categories = list(sample_counts.keys())\n",
        "    names_N = ['dn', 'ca', 'cn']\n",
        "\n",
        "    for mutation in mutation_types:\n",
        "        if sum(names_N[i] in tada_counts[mutation] for i in range(3)) != 3:\n",
        "            return f\"columns of {mutation} do not match the required 'dn' 'ca' 'cn'\"\n",
        "\n",
        "    # Find the number of genes and the number of different kinds of mutations\n",
        "    n_gene = len(mu)  # was m\n",
        "    n_mutation = len(mutation_types)  # was K\n",
        "\n",
        "    BF = pd.DataFrame()\n",
        "    for mutation in mutation_types:\n",
        "        print(f\"working on :: {mutation}\")\n",
        "        BF_mut = np.array([])\n",
        "        for i in range(len(tada_counts[mutation])):\n",
        "            test_BF = calculate_BF(i,tada_counts[mutation], sample_counts[mutation], mu[mutation], mu_frac[mutation], hyperpar[mutation], denovo_only[mutation].item(), pi_gene[mutation])\n",
        "            BF_mut = np.append(BF_mut,test_BF)\n",
        "\n",
        "        BF = pd.concat([BF, pd.DataFrame(BF_mut)], axis=1)\n",
        "    BF.columns = mutation_types\n",
        "    BF.index = tada_counts[mutation].index\n",
        "\n",
        "    # Calculate the overall BF\n",
        "    BF_total = np.exp(np.log(BF).sum(axis=1))\n",
        "\n",
        "    return {'BF': BF, 'BF.total': BF_total}\n",
        "\n",
        "def TADAnull(tada_counts, sample_counts, mu, hyperpar, denovo_only, mu_frac=1, n_rep=100, dn_max=20, ca_max=200, cn_max=200, max_gap=50):\n",
        "    print(\"CALCULATION OF TADA TEST STATISTICS UNDER THE NULL HYPOTHESIS\")\n",
        "    mutation_types = list(hyperpar.keys())\n",
        "    n_mutation = len(mutation_types)\n",
        "    n_samples = len(list(tada_counts.values())[0])\n",
        "\n",
        "    if not isinstance(mu_frac, pd.DataFrame):\n",
        "        mu_frac = pd.DataFrame(np.reshape([[mu_frac] * n_mutation * n_samples],(n_samples,n_mutation)), columns=mutation_types)\n",
        "\n",
        "    #Pre-compute the bayes factors for the denovo data\n",
        "    table_BF_dn = {}\n",
        "    for mutation in mutation_types:\n",
        "        print(f\"working on creating DN table for :: {mutation}\")\n",
        "        x = np.arange(dn_max + 1)\n",
        "        param = hyperpar[mutation]\n",
        "        n = sample_counts[mutation][\"dn\"]\n",
        "\n",
        "        BF = table_BF_dn_wrapper(x, n, mu[mutation] * mu_frac[mutation], param[\"gamma.mean.dn\"], param[\"beta.dn\"])\n",
        "        table_BF_dn[mutation] = pd.DataFrame(BF, columns=[f\"X{value}\" for value in x])\n",
        "\n",
        "    table_BF_cc = {}\n",
        "    for mutation in mutation_types:\n",
        "        if not denovo_only[mutation].item():\n",
        "            print(f\"working on creating CC table for :: {mutation}\")\n",
        "            tada_counts[mutation][\"Ncc\"] = tada_counts[mutation][[\"ca\", \"cn\"]].sum(axis=1)\n",
        "            Ncc = sorted(tada_counts[mutation][\"Ncc\"])\n",
        "            Ncc_gaps = np.diff(Ncc)\n",
        "            i_gap = np.argmax(Ncc_gaps > max_gap)\n",
        "            n_ca = min(ca_max, Ncc[i_gap])\n",
        "            n_cn = min(cn_max, Ncc[i_gap])\n",
        "            x = pd.DataFrame(list(product(range(n_ca + 1), range(n_cn + 1))), columns=[\"ca\", \"cn\"])\n",
        "            param = hyperpar[mutation]\n",
        "            n = sample_counts[mutation][[\"ca\", \"cn\"]]\n",
        "\n",
        "            BF = table_BF_cc_wrapper(\n",
        "                x,\n",
        "                n,\n",
        "                param[\"gamma.mean.CC\"],\n",
        "                param[\"beta.CC\"],\n",
        "                param[\"rho1\"],\n",
        "                param[\"nu1\"],\n",
        "                param[\"rho0\"],\n",
        "                param[\"nu0\"],\n",
        "            )\n",
        "            table_BF_cc[mutation] = BF.values.reshape(n_ca + 1, n_cn + 1)\n",
        "\n",
        "    return {\"table.BF.dn\": table_BF_dn, \"table.BF.cc\": table_BF_cc}\n",
        "\n",
        "\n",
        "def calculate_BF(i_gene, counts, n, mu, mu_frac, hyperpar, denovo_only, pi_gene):\n",
        "    # Wrapper so that lapply can be used to determine the BF for a gene and a particular mutation variant\n",
        "    # i_gene: gene of interest\n",
        "    # counts: counts for a particular variant, dataframe with vectors for dn, ca, cn\n",
        "    # n: total samples counts, dataframe with entries for dn, ca, cn\n",
        "    # mu: vector with mutation rates for the variant of interest for each gene\n",
        "    # mu_frac: fraction to multiply mu with for the variant of interest\n",
        "    # hyperpar: dataframe with entries for gamma.mean.dn, beta.dn, gamma.mean.CC, beta.CC, rho1, nu1, rho0, nu0 for the\n",
        "    #           variant of interest\n",
        "    # denovo_only: Boolean vector indicating whether only denovo contribution (denovo_only = True) or a combination of\n",
        "    #              denovo and case-control contributions is to be used (denovo_only=False)\n",
        "    # pi_gene: vector with K vectors of estimated fractions of causal variants, one for each class of variants.\n",
        "    #          These fractions will be used to set gene-specific RR (case-control)\n",
        "\n",
        "    if i_gene % 100 == 0 or i_gene == len(counts):\n",
        "        pbar = tqdm(total=len(counts))\n",
        "\n",
        "    ### set the hyper parameters for this gene\n",
        "    hyperpar_gene = hyperpar.copy()\n",
        "    RR_product = hyperpar_gene['gamma.mean.CC'] * hyperpar_gene['beta.CC']\n",
        "    hyperpar_gene['gamma.mean.CC'] = hyperpar_gene['gamma.mean.CC'] * pi_gene[i_gene] + (1 - pi_gene[i_gene])\n",
        "    hyperpar_gene['beta.CC'] = RR_product / hyperpar_gene['gamma.mean.CC']\n",
        "    # Determine the BAYES factor\n",
        "    BF = bayes_factor(x=counts.iloc[i_gene, :], n=n, mu=mu[i_gene] * mu_frac, param=hyperpar_gene, denovo_only=denovo_only)\n",
        "\n",
        "    if i_gene % 100 == 0 or i_gene == len(counts):\n",
        "        pbar.update(i_gene)\n",
        "        pbar.close()\n",
        "\n",
        "    return BF\n",
        "\n",
        "def bayes_factor(x, n, mu, param, denovo_only):\n",
        "    # Bayes factor of the gene combining de novo and case-control\n",
        "    # x: a list of (dn, ca, cn), counts in de novo, cases and controls\n",
        "    # n: a list of (dn, ca, cn), sample sizes\n",
        "    # param: (gamma.mean.dn, beta.dn, gamma.mean.CC, beta.CC, rho1, nu1, rho0, nu0)\n",
        "    # denovo_only: Boolean indicating whether only denovo contribution (True) or a combination of\n",
        "    #              denovo and case-control contributions is to be used (False)\n",
        "    # Prior distribution of RR in de novo: gamma.dist.dn ~ Gamma(gamma.mean.dn * beta.dn, beta.dn)\n",
        "    # Prior distribution of RR in C/C data: gamma.dist.cc ~ Gamma(gamma.mean.CC * beta.CC, beta.CC)\n",
        "    # Prior distribution of q|H1: Gamma(rho1, nu1)\n",
        "    # Prior distribution of q|H0: Gamma(rho0, nu0)\n",
        "\n",
        "    # Contribution of denovo variants in families\n",
        "    BF_dn = bayes_factor_dn(x_dn=x['dn'], n_dn=n['dn'], mu=mu, gamma_dn=param['gamma.mean.dn'], beta_dn=param['beta.dn'])\n",
        "    if not denovo_only:\n",
        "        # Contribution of variants in cases and controls\n",
        "        BF_cc = bayes_factor_cc(x_cc=x[['ca', 'cn']], n_cc=n[['ca', 'cn']], gamma_cc=param['gamma.mean.CC'], beta_cc=param['beta.CC'],\n",
        "                                rho1=param['rho1'], nu1=param['nu1'], rho0=param['rho0'], nu0=param['nu0'])\n",
        "    else:\n",
        "        BF_cc = 1\n",
        "    # Combine the pieces of information\n",
        "    # print(\"dn\",BF_dn)\n",
        "    # print(\"cc\",BF_cc)\n",
        "    BF = BF_dn * BF_cc\n",
        "    return BF\n",
        "\n",
        "def bayes_factor_dn(x_dn, n_dn, mu, gamma_dn, beta_dn):\n",
        "    # Bayes factor of de novo counts of a gene\n",
        "    # x_dn: the de novo count\n",
        "    # n_dn: the sample size (number of families)\n",
        "    # mu: the mutation rate (of this type of mutational events)\n",
        "    # Prior distribution of RR: gamma ~ Gamma(gamma_dn * beta_dn, beta_dn)\n",
        "    marg_lik0 = poisson.pmf(x_dn, 2 * n_dn * mu)\n",
        "    marg_lik1 = nbinom.pmf(x_dn, gamma_dn * beta_dn, beta_dn / (beta_dn + 2 * n_dn * mu))\n",
        "    BF = marg_lik1 / marg_lik0\n",
        "    return BF\n",
        "\n",
        "\n",
        "def bayes_factor_cc(x_cc, n_cc, gamma_cc, beta_cc, rho1, nu1, rho0, nu0):\n",
        "    # Bayes factor of the case-control data\n",
        "    # BF_cn and BF_ca: contribution from control and case data, respectively\n",
        "    # Input: the count data x_cc, the sample size n_cc and the parameters gamma_cc, beta_cc, rho1 and nu1\n",
        "    # Prior distribution of RR: gamma ~ Gamma(gamma_cc * beta_cc, beta_cc)\n",
        "    # Prior distribution of q|H1: Gamma(rho1, nu1)\n",
        "    # Prior distribution of q|H0: Gamma(rho0, nu0)\n",
        "    marglik0_cc = evidence_null_cc(x_cc, n_cc, rho0, nu0)\n",
        "    marglik1_cc = evidence_alt_cc(x_cc, n_cc, gamma_cc, beta_cc, rho1, nu1)\n",
        "    BF_cn = marglik1_cc[\"cn\"] / marglik0_cc[\"cn\"]\n",
        "    BF_ca = marglik1_cc[\"ca\"] / marglik0_cc[\"ca\"]\n",
        "    BF = BF_cn * BF_ca\n",
        "    return BF\n",
        "\n",
        "def evidence_null_cc(x_cc, n_cc, rho0, nu0):\n",
        "    # model evidence of case-control data: P(x_1,x_0|H_0)\n",
        "    # Input: the count data x_cc, the sample size n_cc, and the rho0 and nu0\n",
        "    # Prior distribution of q|H0: Gamma(rho0, nu0)\n",
        "    marglik0_ctrl_log = np.log(nbinom.pmf(x_cc[\"cn\"], rho0, nu0 / (nu0 + n_cc[\"cn\"])))\n",
        "    marglik0_case_log = np.log(nbinom.pmf(x_cc[\"ca\"], rho0 + x_cc[\"cn\"], (nu0 + n_cc[\"cn\"]) / (nu0 + n_cc[\"cn\"] + n_cc[\"ca\"])))\n",
        "    marglik0_log = marglik0_ctrl_log + marglik0_case_log\n",
        "\n",
        "    return {\"cn\": np.exp(marglik0_ctrl_log), \"ca\": np.exp(marglik0_case_log), \"total\": np.exp(marglik0_log)}\n",
        "\n",
        "def evidence_alt_cc(x_cc, n_cc, gamma_cc, beta_cc, rho1, nu1, q_lower=1e-8, q_upper=0.1, debug=False):\n",
        "    # model evidence of case-control data: P(x_1,x_0|H_1)\n",
        "    # Input: the count data x_cc, the sample size n_cc, and the parameters gamma_cc, beta_cc, rho1, and nu1\n",
        "    # Prior distribution of RR: gamma ~ Gamma(gamma_cc*beta_cc, bet a_cc)\n",
        "    # Prior distribution of q|H1: Gamma(rho1, nu1)\n",
        "    def integrand(u):\n",
        "        q = np.exp(u)\n",
        "        return (nbinom.pmf(x_cc[\"ca\"], gamma_cc * beta_cc, beta_cc / (beta_cc + n_cc[\"ca\"] * q)) *\n",
        "                gamma.pdf(q, rho1 + x_cc[\"cn\"], scale= 1 / (nu1 + n_cc[\"cn\"])) * np.exp(u))\n",
        "\n",
        "    marglik1_ctrl = nbinom.pmf(x_cc[\"cn\"], rho1, nu1 / (nu1 + n_cc[\"cn\"]))\n",
        "    integrate.quad(integrand, np.log(q_lower), np.log(q_upper))[0]\n",
        "    marglik1_case = integrate.quad(integrand, np.log(q_lower), np.log(q_upper))[0]\n",
        "    marglik1 = marglik1_ctrl * marglik1_case\n",
        "\n",
        "    return {\"cn\": marglik1_ctrl, \"ca\": marglik1_case, \"total\": marglik1}\n",
        "def table_BF_dn_wrapper(i_x, x, n_dn, mu, gamma_dn, beta_dn):\n",
        "    # a wrapper function used for generating the denovo table, see bayes.factor.dn for a description of the variables\n",
        "    BF = bayes_factor_dn(x[i_x], n_dn=n_dn, mu=mu, gamma_dn=gamma_dn, beta_dn=beta_dn)\n",
        "    return BF\n",
        "\n",
        "\n",
        "def table_BF_cc_wrapper(i_x, x, n_cc, gamma_cc, beta_cc, rho1, nu1, rho0, nu0):\n",
        "    # a wrapper function used for generating the case-control table, see bayes.factor.cc for a description of the variables\n",
        "    if (i_x % 100 == 0 or i_x == len(x)) and len(x) > 1000:\n",
        "        pb = tqdm(total=len(x))\n",
        "        pb.update(i_x)\n",
        "    BF = bayes_factor_cc(x[i_x], n_cc=n_cc, gamma_cc=gamma_cc, beta_cc=beta_cc, rho1=rho1, nu1=nu1, rho0=rho0, nu0=nu0)\n",
        "    return BF\n",
        "\n",
        "def permute_gene(i_gene, mu_rate, counts, n, n_rep, param, denovo_only, table_cc, table_dn):\n",
        "    # Compute permutation BFs of one gene\n",
        "    # mu_rate: the mutation rate of a gene for the variant of interest\n",
        "    # counts: dn, ca, and co counts for the variant of interest to be permuted, this also has a column for Ncc=ca+cn\n",
        "    # n: sample size, for values for de novo, case, control, and case+control\n",
        "    # n_rep: number of permutation_types\n",
        "    # param: set of hyper parameters for the variant of interest.\n",
        "    # table_cc: table of precomputed BFs for case control events of size max.ca by max.cn for the variant of interest\n",
        "    # table_dn: table of precomputed BFs for denovo events of size number of genes by max.dn for the variant of interest\n",
        "    # Output: vector of n_rep BF generated under the null hypothesis\n",
        "\n",
        "    if i_gene % 100 == 0 or i_gene == counts.shape[0]:\n",
        "        print(f\"Progress: {i_gene}/{counts.shape[0]}\")\n",
        "\n",
        "    # generate permutation data for denovo events\n",
        "    sample_dn = np.random.poisson(2 * n_rep * mu_rate[i_gene], size=n_rep)\n",
        "    # look up the BF value in the table\n",
        "    BF_dn = table_dn[i_gene, sample_dn]\n",
        "\n",
        "    if not denovo_only:\n",
        "        # when both denovo and case-control BF are needed\n",
        "        # generate permutation data for case-control events\n",
        "        max_ca = table_cc.shape[0]\n",
        "        max_cn = table_cc.shape[1]\n",
        "        sample_ca = np.zeros(n_rep)\n",
        "        sample_cn = np.zeros(n_rep)\n",
        "\n",
        "        for j in range(n_rep):\n",
        "            sample_ca[j] = np.random.hypergeometric(counts[\"Ncc\"][i_gene], n[\"ca\"] + n[\"cn\"] - counts[\"Ncc\"][i_gene], n[\"ca\"])\n",
        "            sample_cn[j] = counts[\"Ncc\"][i_gene] - sample_ca[j]\n",
        "\n",
        "        # find the generated counts that are outside of the pre-computed table\n",
        "        i_na = np.where((sample_ca + 1 > max_ca) | (sample_cn + 1 > max_cn))[0]\n",
        "        if len(i_na) > 0:\n",
        "            # calculate their BF on a case by case basis\n",
        "            BF_na = np.zeros(len(i_na))\n",
        "            for idx, i in enumerate(i_na):\n",
        "                BF_na[idx] = table_BF_cc_wrapper(data={\"ca\": sample_ca[i], \"cn\": sample_cn[i]},\n",
        "                                                 n_cc=n[[\"ca\", \"cn\"]],\n",
        "                                                 gamma_cc=param[\"gamma.mean.CC\"],\n",
        "                                                 beta_cc=param[\"beta.CC\"],\n",
        "                                                 rho1=param[\"rho1\"],\n",
        "                                                 nu1=param[\"nu1\"],\n",
        "                                                 rho0=param[\"rho0\"],\n",
        "                                                 nu0=param[\"nu0\"])\n",
        "\n",
        "        # set the counts outside the range to missing\n",
        "        sample_ca[sample_ca + 1 > max_ca] = np.nan\n",
        "        sample_cn[sample_cn + 1 > max_cn] = np.nan\n",
        "\n",
        "        # gather the BF values that can be taken from the pre-computed table\n",
        "        BF_cc = table_cc[sample_ca + 1, sample_cn + 1]\n",
        "\n",
        "        # replace the missing values with the pre-computed ones\n",
        "        i_na = np.where(np.isnan(BF_cc))[0]\n",
        "        if len(i_na) > 0:\n",
        "            BF_cc[i_na] = BF_na\n",
        "\n",
        "    else:\n",
        "        # if denovo only needed then set BF_dn to 1\n",
        "        BF_cc = np.ones(n_rep)\n",
        "\n",
        "    # determine the total BF from the two components\n",
        "    BF = BF_cc * BF_dn\n",
        "\n",
        "    return BF\n",
        "\n",
        "def Bayesian_FDR(BF, pi0):\n",
        "    # Bayesian FDR control (PMID:19822692, Section2.3)\n",
        "    # BF: a vector of BFs\n",
        "    # pi0: the prior probability that the null model is true\n",
        "    # Return: the q-value of each BF, and the number of findings with q below alpha.\n",
        "\n",
        "    # order the BF in decreasing order, need to retain order to get results back in proper order\n",
        "    i_order = np.argsort(-BF)\n",
        "    BF = BF[i_order]\n",
        "\n",
        "    # convert BFs to PPA (posterior probability of alternative model)\n",
        "    pi = 1 - pi0\n",
        "    q = pi * BF / (1 - pi + pi * BF)  # PPA\n",
        "    q0 = 1 - q  # posterior probability of null model\n",
        "\n",
        "    # the FDR at each PPA cutoff\n",
        "    FDR = np.cumsum(q0) / np.arange(1, len(BF) + 1)\n",
        "\n",
        "    # reorder to the original order\n",
        "    FDR[i_order] = FDR\n",
        "\n",
        "    return FDR\n",
        "\n",
        "def bayesFactor_pvalue(BF, BF_null):\n",
        "    # determines the p-value for the BF using permutation_types under the null hypothesis BF_null\n",
        "    # BF: vector with bayes factors based on the data\n",
        "    # BF_null: vector with bayes factors based on permuted data\n",
        "\n",
        "    BF_null = np.sort(BF_null)[::-1]\n",
        "    pval = np.searchsorted(-BF_null, -BF) / len(BF_null)\n",
        "    pval[pval == 0] = 0.5 / len(BF_null)\n",
        "\n",
        "    return pval\n",
        "\n",
        "def denovo_MOM(k, N, mu, C, beta, d=2, S=100, max_kvec=None):\n",
        "    # Estimating relative risk and the number of multiple hits from de novo data\n",
        "    # Input:  k - number of disease genes\n",
        "    #         N - sample size\n",
        "    #         mu - mutation rate for all genes\n",
        "    #         C - observed number of de novo events\n",
        "    #         beta - parameter of the prior distribution of gamma\n",
        "    #         d - number of events to use (1 is 1 or more, 2 is 2 or more)\n",
        "    #         S - number of samples to generate per gene\n",
        "    #         max_kvec - used to generate a time line.\n",
        "    # Output: gamma_mean - the average relative risk,\n",
        "    #         M - the expected number of multi-hit genes\n",
        "\n",
        "    if max_kvec is not None:\n",
        "        if k % 100 == 0 or k == max_kvec:\n",
        "            pb = tqdm(total=max_kvec)\n",
        "            pb.update(k)\n",
        "\n",
        "    m = len(mu)  # number of genes\n",
        "\n",
        "    # enrichment of de novo events\n",
        "    nu = C / (2 * N * np.sum(mu))\n",
        "\n",
        "    # MOM estimator of gamma_mean\n",
        "    gamma_mean = (nu - 1) * m / k + 1\n",
        "\n",
        "    # expected M (choose d = 2)\n",
        "    rs = count_multihit(N, mu, k / m, gamma_mean, beta, d=d, S=S)\n",
        "    M = np.sum(rs['M1']) + np.sum(rs['M0'])\n",
        "\n",
        "    return {'gamma.mean': gamma_mean, 'M': M}\n",
        "\n",
        "\n",
        "def count_multihit(N, mu, pi, gamma_mean, beta, d, S):\n",
        "    # Estimate the number of multihit genes in a genome.\n",
        "    # N: sample size\n",
        "    # mu: mutation rate for all genes\n",
        "    # pi: ratio of number of risk genes and total number of genes\n",
        "    # gamma_mean: the average relative risk\n",
        "    # beta: parameter of the prior distribution of gamma\n",
        "    # d: number of events to use (1 is 1 or more, 2 is 2 or more)\n",
        "    # S: number of samples to generate per gene\n",
        "    # Output: M0 - number of multiple-hit genes for the non-risk genes\n",
        "    #         M1 - number of multiple-hit genes for risk genes\n",
        "\n",
        "    m = len(mu)\n",
        "\n",
        "    # M1: the number of causal genes having d or more de novo mutation_types\n",
        "    p_alt = np.column_stack([multihit_prob(mu_i, N, gamma_mean, beta, d=d, S=S) for mu_i in mu])\n",
        "    M1 = m * pi * np.mean(p_alt, axis=0)\n",
        "\n",
        "    # M0: the number of non-causal genes having d or more de novo mutation_types\n",
        "    p_null = np.column_stack([(1 - poisson.cdf(d_i, 2 * N * mu_i)) for mu_i in mu for d_i in d])\n",
        "    p_null = p_null.reshape(m, len(d))\n",
        "    M0 = m * (1 - pi) * np.mean(p_null, axis=0)\n",
        "\n",
        "    result = pd.DataFrame({'d': d, 'M0': M0, 'M1': M1})\n",
        "    return result\n",
        "\n",
        "def multihit_prob(mu, N, gamma_mean, beta, d, S):\n",
        "    # Prob. of having d or more de novo mutation_types under H1\n",
        "    # Use simulation, but could also use analytic form\n",
        "    # mu: mutation rate for a gene\n",
        "    # N: sample size\n",
        "    # gamma_mean: the average relative risk\n",
        "    # beta: parameter of the prior distribution of gamma\n",
        "    # d: number of events to use (1 is 1 or more, 2 is 2 or more)\n",
        "    # S: number of samples to generate per gene\n",
        "    # Output: p - average probability of having d or more de novo mutation_types\n",
        "\n",
        "    gamma = gamma.rvs(gamma_mean * beta, scale=1 / beta, size=S)\n",
        "    p = 1 - poisson.cdf(d, 2 * N * mu * gamma)\n",
        "    return np.mean(p)\n",
        "\n",
        "# Read mutation data\n",
        "tada_file = \"TADA_demo_counts_de-novo_and_inherited.txt\"\n",
        "tada_data = pd.read_table(tada_file)\n",
        "\n",
        "# Specify the number of families and the number of cases and control samples included in the analysis\n",
        "n_family = 4500\n",
        "n_case = 1000\n",
        "n_ctrl = 3000\n",
        "\n",
        "data = {'dn': [n_family], 'ca': [n_case + n_family], 'cn': [n_ctrl + n_family]}\n",
        "n = pd.DataFrame(data)\n",
        "sample_counts = {'cls1': n, 'cls2': n}\n",
        "\n",
        "# Create the mutational data used by TADA\n",
        "cls1_counts = pd.DataFrame({'dn': tada_data['dn.cls1'],\n",
        "                            'ca': tada_data['trans.cls1'] + tada_data['case.cls1'],\n",
        "                            'cn': tada_data['ntrans.cls1'] + tada_data['ctrl.cls1']})\n",
        "cls1_counts.index = tada_data['gene.id']\n",
        "\n",
        "cls2_counts = pd.DataFrame({'dn': tada_data['dn.cls2'],\n",
        "                            'ca': tada_data['trans.cls2'] + tada_data['case.cls2'],\n",
        "                            'cn': tada_data['ntrans.cls2'] + tada_data['ctrl.cls2']})\n",
        "cls2_counts.index = tada_data['gene.id']\n",
        "\n",
        "tada_counts = {'cls1': cls1_counts, 'cls2': cls2_counts}\n",
        "\n",
        "# Set up mutation rates\n",
        "mu = pd.DataFrame({'cls1': tada_data['mut.cls1'], 'cls2': tada_data['mut.cls2']})\n",
        "\n",
        "# Set up denovo only TRUE/FALSE, here we do not want to restrict ourselves to de novo only analyses\n",
        "denovo_only = pd.DataFrame({'cls1': [False], 'cls2': [False]})\n",
        "\n",
        "# Set up parameters\n",
        "cls1_params = pd.DataFrame({'gamma.mean.dn': [20.0],\n",
        "                            'beta.dn': [1],\n",
        "                            'gamma.mean.CC': [2.3],\n",
        "                            'beta.CC': [4.0],\n",
        "                            'rho1': [0.1],\n",
        "                            'nu1': [100],\n",
        "                            'rho0': [0.1],\n",
        "                            'nu0': [100]})\n",
        "\n",
        "cls2_params = pd.DataFrame({'gamma.mean.dn': [4.7],\n",
        "                            'beta.dn': [1],\n",
        "                            'gamma.mean.CC': [1.0],\n",
        "                            'beta.CC': [1000],\n",
        "                            'rho1': [0.15],\n",
        "                            'nu1': [100],\n",
        "                            'rho0': [0.15],\n",
        "                            'nu0': [100]})\n",
        "\n",
        "hyperpar = {'cls1': cls1_params, 'cls2': cls2_params}\n",
        "# Running TADA\n",
        "re_TADA = TADA(tada_counts=tada_counts, sample_counts=sample_counts, mu=mu, hyperpar=hyperpar, denovo_only=denovo_only)\n"
      ],
      "metadata": {
        "id": "CsUYLh75Jhgp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db37ada4-0101-4c73-e37b-a54d4b6b8491"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CALCULATION OF TADA TEST STATISTICS\n",
            "checking the input for consistent variable names\n",
            "working on :: cls1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5000 [00:01<?, ?it/s]\n",
            "  2%|▏         | 100/5000 [00:00<00:21, 223.99it/s]\n",
            "  4%|▍         | 200/5000 [00:00<00:05, 886.96it/s]\n",
            "  6%|▌         | 300/5000 [00:00<00:03, 1181.31it/s]\n",
            "  8%|▊         | 400/5000 [00:00<00:02, 1809.39it/s]\n",
            " 10%|█         | 500/5000 [00:00<00:02, 1530.27it/s]\n",
            " 12%|█▏        | 600/5000 [00:00<00:03, 1327.40it/s]\n",
            " 14%|█▍        | 700/5000 [00:00<00:02, 1483.21it/s]\n",
            " 16%|█▌        | 800/5000 [00:00<00:02, 1735.89it/s]\n",
            " 18%|█▊        | 900/5000 [00:00<00:02, 1644.90it/s]\n",
            " 20%|██        | 1000/5000 [00:00<00:01, 2595.70it/s]\n",
            " 22%|██▏       | 1100/5000 [00:00<00:01, 3267.93it/s]\n",
            " 24%|██▍       | 1200/5000 [00:00<00:00, 4897.81it/s]\n",
            " 26%|██▌       | 1300/5000 [00:00<00:02, 1719.96it/s]\n",
            " 28%|██▊       | 1400/5000 [00:00<00:00, 4392.42it/s]\n",
            " 30%|███       | 1500/5000 [00:00<00:00, 4053.12it/s]\n",
            " 32%|███▏      | 1600/5000 [00:00<00:00, 4423.20it/s]\n",
            " 34%|███▍      | 1700/5000 [00:00<00:00, 7880.95it/s]\n",
            " 36%|███▌      | 1800/5000 [00:00<00:00, 4953.50it/s]\n",
            " 38%|███▊      | 1900/5000 [00:00<00:00, 5066.26it/s]\n",
            " 40%|████      | 2000/5000 [00:00<00:00, 7071.70it/s]\n",
            " 42%|████▏     | 2100/5000 [00:00<00:00, 6490.05it/s]\n",
            " 44%|████▍     | 2200/5000 [00:00<00:00, 7227.94it/s]\n",
            " 46%|████▌     | 2300/5000 [00:00<00:00, 7814.51it/s]\n",
            " 48%|████▊     | 2400/5000 [00:00<00:00, 7108.05it/s]\n",
            " 50%|█████     | 2500/5000 [00:00<00:00, 5838.50it/s]\n",
            " 52%|█████▏    | 2600/5000 [00:00<00:00, 4662.35it/s]\n",
            " 54%|█████▍    | 2700/5000 [00:00<00:00, 4307.82it/s]\n",
            " 56%|█████▌    | 2800/5000 [00:00<00:00, 12061.39it/s]\n",
            " 58%|█████▊    | 2900/5000 [00:00<00:00, 13221.32it/s]\n",
            " 60%|██████    | 3000/5000 [00:00<00:00, 9186.93it/s]\n",
            " 62%|██████▏   | 3100/5000 [00:00<00:00, 4384.37it/s]\n",
            " 64%|██████▍   | 3200/5000 [00:00<00:00, 8838.88it/s]\n",
            " 66%|██████▌   | 3300/5000 [00:00<00:00, 14343.22it/s]\n",
            " 68%|██████▊   | 3400/5000 [00:00<00:00, 11177.91it/s]\n",
            " 70%|███████   | 3500/5000 [00:00<00:00, 16928.22it/s]\n",
            " 72%|███████▏  | 3600/5000 [00:00<00:00, 9499.51it/s]\n",
            " 74%|███████▍  | 3700/5000 [00:00<00:00, 16681.81it/s]\n",
            " 76%|███████▌  | 3800/5000 [00:00<00:00, 16914.63it/s]\n",
            " 78%|███████▊  | 3900/5000 [00:00<00:00, 10913.72it/s]\n",
            " 80%|████████  | 4000/5000 [00:00<00:00, 13959.95it/s]\n",
            " 82%|████████▏ | 4100/5000 [00:00<00:00, 11989.69it/s]\n",
            " 84%|████████▍ | 4200/5000 [00:00<00:00, 17772.04it/s]\n",
            " 86%|████████▌ | 4300/5000 [00:00<00:00, 10295.37it/s]\n",
            " 88%|████████▊ | 4400/5000 [00:00<00:00, 9299.97it/s]\n",
            " 90%|█████████ | 4500/5000 [00:00<00:00, 14375.91it/s]\n",
            " 92%|█████████▏| 4600/5000 [00:00<00:00, 21650.77it/s]\n",
            " 94%|█████████▍| 4700/5000 [00:00<00:00, 15759.65it/s]\n",
            " 96%|█████████▌| 4800/5000 [00:00<00:00, 16550.27it/s]\n",
            " 98%|█████████▊| 4900/5000 [00:00<00:00, 11006.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "working on :: cls2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5000 [00:00<?, ?it/s]\n",
            "  2%|▏         | 100/5000 [00:00<00:29, 167.08it/s]\n",
            "  4%|▍         | 200/5000 [00:00<00:13, 348.18it/s]\n",
            "  6%|▌         | 300/5000 [00:00<00:08, 530.66it/s]\n",
            "  8%|▊         | 400/5000 [00:00<00:03, 1390.95it/s]\n",
            " 10%|█         | 500/5000 [00:00<00:02, 1841.01it/s]\n",
            " 12%|█▏        | 600/5000 [00:00<00:04, 1065.23it/s]\n",
            " 14%|█▍        | 700/5000 [00:00<00:04, 951.33it/s]\n",
            " 16%|█▌        | 800/5000 [00:00<00:02, 1711.19it/s]\n",
            " 18%|█▊        | 900/5000 [00:00<00:02, 1635.91it/s]\n",
            " 20%|██        | 1000/5000 [00:00<00:02, 1869.15it/s]\n",
            " 22%|██▏       | 1100/5000 [00:00<00:02, 1360.92it/s]\n",
            " 24%|██▍       | 1200/5000 [00:00<00:01, 3232.68it/s]\n",
            " 26%|██▌       | 1300/5000 [00:00<00:01, 2461.88it/s]\n",
            " 28%|██▊       | 1400/5000 [00:00<00:01, 2875.53it/s]\n",
            " 30%|███       | 1500/5000 [00:00<00:01, 2281.09it/s]\n",
            " 32%|███▏      | 1600/5000 [00:00<00:01, 3299.04it/s]\n",
            " 34%|███▍      | 1700/5000 [00:00<00:00, 5328.35it/s]\n",
            " 36%|███▌      | 1800/5000 [00:00<00:00, 6404.06it/s]\n",
            " 38%|███▊      | 1900/5000 [00:00<00:00, 3232.52it/s]\n",
            " 40%|████      | 2000/5000 [00:00<00:00, 4025.87it/s]\n",
            " 42%|████▏     | 2100/5000 [00:00<00:00, 7250.91it/s]\n",
            " 44%|████▍     | 2200/5000 [00:00<00:00, 4623.13it/s]\n",
            " 46%|████▌     | 2300/5000 [00:00<00:00, 4073.62it/s]\n",
            " 48%|████▊     | 2400/5000 [00:00<00:00, 8901.51it/s]\n",
            " 50%|█████     | 2500/5000 [00:00<00:00, 7680.46it/s]\n",
            " 52%|█████▏    | 2600/5000 [00:00<00:00, 5417.95it/s]\n",
            " 54%|█████▍    | 2700/5000 [00:00<00:00, 4979.25it/s]\n",
            " 56%|█████▌    | 2800/5000 [00:00<00:00, 3553.26it/s]\n",
            " 58%|█████▊    | 2900/5000 [00:00<00:00, 6066.88it/s]\n",
            " 60%|██████    | 3000/5000 [00:00<00:00, 9967.14it/s] \n",
            " 62%|██████▏   | 3100/5000 [00:00<00:00, 5557.87it/s]\n",
            " 64%|██████▍   | 3200/5000 [00:00<00:00, 4079.21it/s]\n",
            " 66%|██████▌   | 3300/5000 [00:00<00:00, 5128.96it/s]\n",
            " 68%|██████▊   | 3400/5000 [00:00<00:00, 9266.13it/s]\n",
            " 70%|███████   | 3500/5000 [00:00<00:00, 9527.28it/s]\n",
            " 72%|███████▏  | 3600/5000 [00:00<00:00, 6372.52it/s]\n",
            " 74%|███████▍  | 3700/5000 [00:00<00:00, 9419.45it/s]\n",
            " 76%|███████▌  | 3800/5000 [00:00<00:00, 6625.58it/s]\n",
            " 78%|███████▊  | 3900/5000 [00:00<00:00, 5020.82it/s]\n",
            " 80%|████████  | 4000/5000 [00:00<00:00, 5190.84it/s]\n",
            " 82%|████████▏ | 4100/5000 [00:00<00:00, 6058.46it/s]\n",
            " 84%|████████▍ | 4200/5000 [00:00<00:00, 9731.65it/s]\n",
            " 86%|████████▌ | 4300/5000 [00:00<00:00, 7890.56it/s]\n",
            " 88%|████████▊ | 4400/5000 [00:00<00:00, 6720.74it/s]\n",
            " 90%|█████████ | 4500/5000 [00:00<00:00, 7177.41it/s]\n",
            " 92%|█████████▏| 4600/5000 [00:00<00:00, 14754.30it/s]\n",
            " 94%|█████████▍| 4700/5000 [00:00<00:00, 9020.17it/s]\n",
            " 96%|█████████▌| 4800/5000 [00:00<00:00, 5951.71it/s]\n",
            " 98%|█████████▊| 4900/5000 [00:00<00:00, 6404.66it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def TADAnull(tada_counts, sample_counts, mu, hyperpar, denovo_only, mu_frac=1, n_rep=100, dn_max=20, ca_max=200, cn_max=200, max_gap=50):\n",
        "    # Genome-wide application of TADA for K classes of variants\n",
        "    # This function determines the distribution of the null hypothesis test statistics which in turn can be used to determine approximate p-values\n",
        "    # tada.counts: list of K data frames in which each dataframe consists of vectors for counts for denovo, case and control mutation counts\n",
        "    # sample.counts: list of K data frames in which each dataframe consists of a vector with three entries of total sample counts,\n",
        "    #                 one for denovo (# trios), cases (# cases + # trios) and controls (# controls + # trios)\n",
        "    # mu: data frame with K vectors of mutation rates. One for each mutation category.\n",
        "    # mu.frac: data frame with the fraction to use for each mutation category K\n",
        "    # hyperpar: list of K data frames. Each data frame consists of entries for gamma.mean.dn, beta.dn, gamma.mean.CC, beta.CC, rho1, nu1, rho0, nu0\n",
        "    # denovo.only: data frame with K Boolean variables of indicating whether only denovo counts should be used (T) or whether both denovo and case-control\n",
        "    # counts be used (F).\n",
        "    # n_rep: number of repetitions to use recommended to be at least 100. For smaller numbers of genes n_rep should be increased.\n",
        "    # dn.max: number of denovo events for which the BF is pre-computed and stored in a table. This speeds up the simulation process. The function will use dn.max or\n",
        "    #         the maximum number of denovo events for a gene, whichever is smaller.\n",
        "    # ca.max and cn.max: as dn.max this is used to pre-compute a table of common case-control count events to speed up processing. The larger these numbers, the longer the\n",
        "    #                     the longer the pre computation step takes. For very large values of ca.max and cn.max an intergration error might occur.\n",
        "    # max.gap: this is used internally to control the size of the pre-compution of the case-control BF matrix. It represents the gap between two genes in\n",
        "    #           case-control count when ordered from smallest to largest count. This essentially identifies outlying values that hardly ever happen and do not have to be\n",
        "    #           pre-computed.\n",
        "    # Output: dataframe with BFnull for each of the K classes of variants as well as BFnull.total. One entry for each of the genes times n_rep.\n",
        "\n",
        "    print(\"CALCULATION OF TADA TEST STATISTICS UNDER THE NULL HYPOTHESIS\")\n",
        "    mutation_types = list(tada_counts.keys())\n",
        "    n_mutation = len(mutation_types)\n",
        "    n_samples = len(list(tada_counts.values())[0])\n",
        "\n",
        "    # Make sure mu_frac and pi_gene are data frames\n",
        "    if not isinstance(mu_frac, pd.DataFrame):\n",
        "        mu_frac = pd.DataFrame(np.reshape([[mu_frac] * n_mutation],(1,n_mutation)), columns=mutation_types)\n",
        "\n",
        "    #Pre-compute the bayes factors for the denovo data\n",
        "    table_BF_dn = {}\n",
        "    for mutation in mutation_types:\n",
        "        print(f\"working on creating DN table for :: {mutation}\")\n",
        "        x = np.arange(dn_max + 1)\n",
        "        counts = tada_counts[mutation]['dn']\n",
        "        param = hyperpar[mutation]\n",
        "        n = sample_counts[mutation]['dn']\n",
        "        BF = np.array([])\n",
        "        for i in range(len(x)):\n",
        "            BF_i = bayes_factor_dn(counts.iloc[i], n_dn=n, mu=mu[mutation][i] * mu_frac[mutation], gamma_dn=param[\"gamma.mean.dn\"], beta_dn=param[\"beta.dn\"])\n",
        "            BF = np.append(BF,BF_i)\n",
        "        table_BF_dn[mutation] = pd.DataFrame(np.reshape(BF,(len(BF)//len(x),len(x))), columns=[f\"X{value}\" for value in x])\n",
        "        print(mutation,\":\",table_BF_dn[mutation])\n",
        "\n",
        "    table_BF_cc = {}\n",
        "    for mutation in mutation_types:\n",
        "        if not denovo_only[mutation].item():\n",
        "            print(f\"working on creating CC table for :: {mutation}\")\n",
        "            tada_counts[mutation][\"Ncc\"] = tada_counts[mutation][[\"ca\", \"cn\"]].sum(axis=1)\n",
        "            Ncc = sorted(tada_counts[mutation][\"Ncc\"])\n",
        "            Ncc_gaps = np.diff(Ncc)\n",
        "            i_gap = np.where(Ncc_gaps > max_gap)[0][0] if len(np.where(Ncc_gaps > max_gap)[0]) > 0 else max(Ncc)\n",
        "            n_ca = min(ca_max, i_gap)\n",
        "            n_cn = min(cn_max, i_gap)\n",
        "            print(\"NCANCN\",n_ca,n_cn)\n",
        "            print(max_gap)\n",
        "            x = pd.DataFrame(list(product(range(n_ca + 1), range(n_cn + 1))), columns=[\"ca\", \"cn\"])\n",
        "            param = hyperpar[mutation]\n",
        "            n = sample_counts[mutation][[\"ca\", \"cn\"]]\n",
        "            BF = np.array([])\n",
        "            for i in range(len(x)):\n",
        "                BF_i = bayes_factor_cc(x.iloc[i], n_cc=n, gamma_cc=param[\"gamma.mean.CC\"], beta_cc=param[\"beta.CC\"], rho1=param[\"rho1\"], nu1=param[\"nu1\"], rho0=param[\"rho0\"], nu0=param[\"nu0\"])\n",
        "                BF = np.append(BF,BF_i)\n",
        "            table_BF_cc[mutation] = pd.DataFrame(np.reshape(BF,(n_ca + 1, n_cn + 1)))\n",
        "\n",
        "\n",
        "    BF = np.array([])\n",
        "    for mutation in mutation_types:\n",
        "        print(\"working on creating null data for ::\", mutation)\n",
        "        BF_col = np.array([])\n",
        "        for i in range(len(tada_counts[mutation])):\n",
        "            print(\"mut\",mu[mutation])\n",
        "            print(\"mufrac:\",mu_frac)\n",
        "            # print(\"counts:\",tada_counts[mutation].iloc[i])\n",
        "            # print(\"sampl:\",sample_counts[mutation])\n",
        "            BF_col = np.append(BF_col,permute_gene(i,mu_rate=mu[mutation][i] * mu_frac[mutation], counts=tada_counts[mutation],\n",
        "                                                        n=sample_counts[mutation], n_rep=n_rep, param=hyperpar[mutation],\n",
        "                                                        denovo_only=denovo_only[mutation],\n",
        "                                                        table_cc=table_BF_cc[mutation], table_dn=table_BF_dn[mutation]))\n",
        "\n",
        "        BF = np.column_stack((BF, BF_col))\n",
        "    BF = pd.DataFrame(BF, index = np.arange(len(BF)),columns=mutation_types)\n",
        "    BF_total = np.exp(np.log(BF).sum(axis=1))\n",
        "\n",
        "    return {'BF_null': BF, 'BF_null.total': BF_total}\n",
        "\n",
        "def bayes_factor_dn(x_dn, n_dn, mu, gamma_dn, beta_dn):\n",
        "    # Bayes factor of de novo counts of a gene\n",
        "    # x_dn: the de novo count\n",
        "    # n_dn: the sample size (number of families)\n",
        "    # mu: the mutation rate (of this type of mutational events)\n",
        "    # Prior distribution of RR: gamma ~ Gamma(gamma_dn * beta_dn, beta_dn)\n",
        "    # print(\"x_dn:\",x_dn)\n",
        "    # print(\"n_dn:\",n_dn)\n",
        "    # print(\"Mu:\",mu)\n",
        "    # print(\"ndnmu:\",2*n_dn*mu)\n",
        "    # print(\"gam\",gamma_dn)\n",
        "    # print(\"bet\",beta_dn)\n",
        "    marg_lik0 = poisson.pmf(x_dn, 2 * n_dn * mu)\n",
        "    marg_lik1 = nbinom.pmf(x_dn, gamma_dn * beta_dn, beta_dn / (beta_dn + 2 * n_dn * mu))\n",
        "    BF = marg_lik1 / marg_lik0\n",
        "    # print(\"margo\",marg_lik0)\n",
        "    # print(\"lik1:\",marg_lik1)\n",
        "    return BF\n",
        "\n",
        "def bayes_factor_cc(x_cc, n_cc, gamma_cc, beta_cc, rho1, nu1, rho0, nu0):\n",
        "    # Bayes factor of the case-control data\n",
        "    # BF_cn and BF_ca: contribution from control and case data, respectively\n",
        "    # Input: the count data x_cc, the sample size n_cc and the parameters gamma_cc, beta_cc, rho1 and nu1\n",
        "    # Prior distribution of RR: gamma ~ Gamma(gamma_cc * beta_cc, beta_cc)\n",
        "    # Prior distribution of q|H1: Gamma(rho1, nu1)\n",
        "    # Prior distribution of q|H0: Gamma(rho0, nu0)\n",
        "    marglik0_cc = evidence_null_cc(x_cc, n_cc, rho0, nu0)\n",
        "    marglik1_cc = evidence_alt_cc(x_cc, n_cc, gamma_cc, beta_cc, rho1, nu1)\n",
        "    BF_cn = marglik1_cc[\"cn\"] / marglik0_cc[\"cn\"]\n",
        "    BF_ca = marglik1_cc[\"ca\"] / marglik0_cc[\"ca\"]\n",
        "    BF = BF_cn * BF_ca\n",
        "    return BF\n",
        "\n",
        "\n",
        "def table_BF_dn_wrapper(i_x, x, n_dn, mu, gamma_dn, beta_dn):\n",
        "    # a wrapper function used for generating the denovo table, see bayes.factor.dn for a description of the variables\n",
        "    BF = bayes_factor_dn(x[i_x], n_dn=n_dn, mu=mu, gamma_dn=gamma_dn, beta_dn=beta_dn)\n",
        "    return BF\n",
        "\n",
        "\n",
        "def table_BF_cc_wrapper(i_x, x, n_cc, gamma_cc, beta_cc, rho1, nu1, rho0, nu0):\n",
        "    # a wrapper function used for generating the case-control table, see bayes.factor.cc for a description of the variables\n",
        "    if (i_x % 100 == 0 or i_x == len(x)) and len(x) > 1000:\n",
        "        pb = tqdm(total=len(x))\n",
        "        pb.update(i_x)\n",
        "    BF = bayes_factor_cc(x[i_x], n_cc=n_cc, gamma_cc=gamma_cc, beta_cc=beta_cc, rho1=rho1, nu1=nu1, rho0=rho0, nu0=nu0)\n",
        "    return BF\n",
        "\n",
        "def permute_gene(i_gene, mu_rate, counts, n, n_rep, param, denovo_only, table_cc, table_dn):\n",
        "    # Compute permutation BFs of one gene\n",
        "    # mu_rate: the mutation rate of a gene for the variant of interest\n",
        "    # counts: dn, ca, and co counts for the variant of interest to be permuted, this also has a column for Ncc=ca+cn\n",
        "    # n: sample size, for values for de novo, case, control, and case+control\n",
        "    # n_rep: number of permutation_types\n",
        "    # param: set of hyper parameters for the variant of interest.\n",
        "    # table_cc: table of precomputed BFs for case control events of size max.ca by max.cn for the variant of interest\n",
        "    # table_dn: table of precomputed BFs for denovo events of size number of genes by max.dn for the variant of interest\n",
        "    # Output: vector of n_rep BF generated under the null hypothesis\n",
        "\n",
        "    if i_gene % 100 == 0 or i_gene == counts.shape[0]:\n",
        "        print(f\"Progress: {i_gene}/{counts.shape[0]}\")\n",
        "\n",
        "    # generate permutation data for denovo events\n",
        "    print(\"nrep\",n_rep)\n",
        "    print(\"mu_rate\",mu_rate)\n",
        "    sample_dn = np.random.poisson(2 * n['dn'] * mu_rate, size=n_rep)\n",
        "    # look up the BF value in the table\n",
        "    print(\"Tabcc\",table_cc)\n",
        "    print(\"tab\",table_dn)\n",
        "    # print(\"i\",i_gene)\n",
        "    # print(\"samp\",sample_dn)\n",
        "    BF_dn = table_dn.iloc[i_gene].iloc[sum(sample_dn)]\n",
        "\n",
        "    if not denovo_only.item():\n",
        "        # when both denovo and case-control BF are needed\n",
        "        # generate permutation data for case-control events\n",
        "        max_ca = table_cc.shape[0]\n",
        "        max_cn = table_cc.shape[1]\n",
        "        sample_ca = np.zeros(n_rep)\n",
        "        sample_cn = np.zeros(n_rep)\n",
        "        for j in range(n_rep):\n",
        "            sample_ca[j] = np.random.hypergeometric(counts[\"Ncc\"][i_gene], n[\"ca\"] + n[\"cn\"] - counts[\"Ncc\"][i_gene], n[\"ca\"])\n",
        "            sample_cn[j] = counts[\"Ncc\"][i_gene] - sample_ca[j]\n",
        "\n",
        "        # find the generated counts that are outside of the pre-computed table\n",
        "        i_na = np.where((sample_ca + 1 > max_ca) | (sample_cn + 1 > max_cn))[0]\n",
        "        if len(i_na) > 0:\n",
        "            # calculate their BF on a case by case basis\n",
        "            BF_na = np.zeros(len(i_na))\n",
        "            for idx, i in enumerate(i_na):\n",
        "                BF_na[idx] = bayes_factor_cc({\"ca\": sample_ca[i], \"cn\": sample_cn[i]},n_cc=n[[\"ca\", \"cn\"]], gamma_cc=param[\"gamma.mean.CC\"], beta_cc=param[\"beta.CC\"], rho1=param[\"rho1\"], nu1=param[\"nu1\"], rho0=param[\"rho0\"], nu0=param[\"nu0\"])\n",
        "\n",
        "        # set the counts outside the range to missing\n",
        "        print(\"ca\",sample_ca)\n",
        "        print(\"cn\",sample_cn)\n",
        "        sample_ca = np.where(sample_ca + 1 > max_ca, np.nan, sample_ca)\n",
        "        sample_cn = np.where(sample_cn + 1 > max_cn, np.nan, sample_cn)\n",
        "        print(\"ca\",sample_ca)\n",
        "        print(\"cn\",sample_cn)\n",
        "        # gather the BF values that can be taken from the pre-computed table\n",
        "        print(max_ca, max_cn)\n",
        "        BF_cc = table_cc[sample_ca + 1, sample_cn + 1]\n",
        "\n",
        "        # replace the missing values with the pre-computed ones\n",
        "        i_na = np.where(np.isnan(BF_cc))[0]\n",
        "        if len(i_na) > 0:\n",
        "            BF_cc[i_na] = BF_na\n",
        "\n",
        "    else:\n",
        "        # if denovo only needed then set BF_dn to 1\n",
        "        BF_cc = np.ones(n_rep)\n",
        "\n",
        "    # determine the total BF from the two components\n",
        "    BF = BF_cc * BF_dn\n",
        "\n",
        "    return BF\n",
        "# Bayesian FDR control\n",
        "re_TADA['qval'] = Bayesian_FDR(re_TADA['BF.total'], pi0=0.95)\n",
        "\n",
        "# Run permutation to get the null distributions to use for calculating p-values for TADA\n",
        "re_TADA_null = TADAnull(tada_counts=tada_counts, sample_counts=sample_counts, mu=mu, hyperpar=hyperpar, denovo_only=denovo_only, n_rep=100)\n",
        "re_TADA['pval'] = bayesFactor_pvalue(re_TADA['BF.total'], re_TADA_null['BFnull.total'])\n",
        "\n",
        "# Top 10 genes based on BF.total\n",
        "top_10_genes = re_TADA.sort_values(by='BF.total', ascending=False).head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7K6u5gcV065B",
        "outputId": "638edc89-9733-4126-a6b0-fb71fb205cc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CALCULATION OF TADA TEST STATISTICS UNDER THE NULL HYPOTHESIS\n",
            "working on creating DN table for :: cls1\n",
            "cls1 :          X0        X1        X2        X3        X4        X5        X6  \\\n",
            "0  0.693934  0.956623  0.830357  0.892679  0.774762  0.542524  0.827411   \n",
            "\n",
            "         X7        X8        X9  ...       X11       X12       X13       X14  \\\n",
            "0  0.962714  0.745576  0.763003  ...  0.746329  0.880481  0.776822  0.793714   \n",
            "\n",
            "        X15       X16       X17       X18       X19       X20  \n",
            "0  0.594788  0.971305  0.785916  0.658306  0.744729  0.884978  \n",
            "\n",
            "[1 rows x 21 columns]\n",
            "working on creating DN table for :: cls2\n",
            "cls2 :          X0        X1        X2       X3        X4       X5        X6  \\\n",
            "0  3.401512  0.554567  0.811788  2.96513  0.282062  0.90493  0.936111   \n",
            "\n",
            "         X7        X8        X9  ...       X11       X12       X13       X14  \\\n",
            "0  4.480005  0.661991  0.658658  ...  0.734978  0.322088  0.691336  0.675868   \n",
            "\n",
            "        X15       X16       X17       X18       X19      X20  \n",
            "0  0.781899  0.358492  0.853938  0.577777  1.354098  0.75519  \n",
            "\n",
            "[1 rows x 21 columns]\n",
            "working on creating CC table for :: cls1\n",
            "NCANCN 44 44\n",
            "50\n",
            "working on creating CC table for :: cls2\n",
            "NCANCN 200 200\n",
            "50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bcdbQTUyQY_p"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}